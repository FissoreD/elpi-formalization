
\section{Determinacy analysis}\label{sec:thm}

% \begin{definition}[Functionality (\isfunc)]\label{def:is-func}
%   Given a program \prog and a term $t$,
%   \isdet\ is defined as follows:
%   $$\forall a\ \subst, \isFuncCmd{t}$$
% \end{definition}

In this section, we are interested in identifying predicates that leave no choice points.
They are called \emph{semidet} in \cite{1996henderson}, or
\emph{operationally deterministic} in
\cite{nakamura1986}.
% Due to the lack of space, we leave the
% proofs of the following theorems in the appendix.

\begin{definition}[Operational determinacy (\isdet)]\label{def:is-det}
  Given a program \prog and a term $\predt$,
  we say that \isdet\ \prog\ {(\predt)} holds iff
  $$\forall a\ \subst, \isDetCmd{\predt}$$
\end{definition}

% \noindent Said in other words, a predicate call \isdet if its execution does not
% create choice points. 
% Without loss of generality, we can rephrase the lemma in
% the following way:

% \begin{definition}[Operational determinacy empty prog (\isdetE)]\label{def:is-det-empty}
%   The execution of an atom $t$ is deterministic iff
%   $$\forall a\ \subst, \isDetCmd[\EmptyList]{t}$$
% \end{definition}

% \noindent The main difference from the first definition is that we begin with an
% empty program and handle a generic term \( t \). Notably, due to the implication
% operator, this second definition remains equivalent to the first, as local
% clauses can be dynamically loaded during the evaluation of \( t \), thereby
% reconstructing the same program referenced in \cref{def:is-det}.  

\def\atomtoprog{\ensuremath{\mathcal{T}}}

% \begin{definition}[Split atom (\atomtoprog)]
%   Given $\Ainst = \piImplCmd[ty_1]{x_1}{c_1}{\dots \impl\
%   \piImplCmd[ty_n]{x_n}{c_n}{s}}$, then $\atomtoprog(\prog) = \langle \{c_n,\cdots,c_1\}, s \rangle$ 
% \end{definition}

% \begin{lemma}
%   Given an atom $\Ainst$ and let $(\prog, \Ainst') = \atomtoprog(\Ainst)$, then
%   $$\isdetE\ \Ainst \Rightarrow \isdet\ \prog\ \Ainst'$$
%   \label{th:run-empty}
% \end{lemma}


\textcolor{red}{
  We assign to signatures a logic formula, a formal meaning, by recursion. We use
  the notation $\sem{\func}\ t$ to translate a signature (\detI\ or \relI) of a
  full applied term $t$ and $\semi{\func_i}\ t'$ for the translation of a generic
  term $t'$. After the definition of the two notation, we briefly explain them.
}

% Thanks to the definition of \isdet, we can provide the semantics of determinacy
% signatures.
% The intuition is given by the following formula.

\begin{definition}[Meaning of a signature]\label{def:sem}
  \textcolor{red}{Given a signature $\func$, a term (\predt)
    a program $\prog$ and a context \ctx, the meaning of a signature
    $\sem{\func}\ \prog\ (\predt)$ is recursively defined as follows.}
  \newcommand{\funcF}[1][]{\ensuremath{\mathcal{F}#1}}
  % \begingroup\makeatletter\def\f@size{8}\check@mathfonts
  $$
    \arraycolsep=1.4pt
    \begin{array}{rll}
      \sem{\detI}\ \prog\ (\predt) = &                                                                      %
      \bigwedge \vecL{\semi{\func_i}\ \prog\ t_i} \Rightarrow \isdet\ \prog\ {(\predt)} \bigwedge \vecL{\semi{\func_o}\ \prog\ t_o} %
                                     & \quad\mathrm{s.t.\ } \ctx\ \pred{} = \dtype{\detI}{\func_i}{\func_o} \\
    \end{array}
  $$
  $$
    \arraycolsep=1.4pt
    \begin{array}{ccc}
      \semi{\detI}\ \prog\ (\predt) = \isdet\ \prog\ (\predt) &
      \qquad \semi{\relI}\ \prog\ (\predt) = \top             &
      \qquad \semi{\expI}\ \prog\ (\predt) = \top \vspace{0.5em}
    \end{array}
  $$

  \noindent
  \textcolor{red}{The notation $\semi{\func}\ \prog\ (\predt)$ is for base cases.
    Moreover, it is extended to deal with partial applications (like \elpiIn{once
      likes} in the introduction). This requires the following extra-rules:}
  $$
    \arraycolsep=1.4pt
    \begin{array}{rl}

      \semi{\dtype{\detI}{\func_i}{\func_o}}\ \prog\ (\predt) =    &                                                                                                                                       %
      \forall \vec{u}\ \vec{v},
      %|\func[_i]| = |\vec{u}| \land |\func[_o]| = |\vec{v}| %
      %\land 
      \bigwedge \vecL{\semi{\func_i}\ u} \Rightarrow \isdet\ \prog\ {(\pred\ (\vec{t}\ \vec{u}\ \vec{v}))} \bigwedge \vecL{\semi{\funcF}\ t_i}                                                             \\
                                                                   & \mathrm{where\ } |\func[_i]| = |\vec{u}| \mathrm{\ and\ } |\func[_o]| = |\vec{v}|                                                     %
      \mathrm{\ and\ } \ctx\ \pred{} = \dtype{\detI}{(\funcF \  \func_i)}{\func_o} \vspace{0.5em}                                                                                                          \\
      \semi{\dtype{\detI}{\EmptyList}{\func_o}}\ \prog\ (\predt) = &                                                                                                                                       %
      \forall \vec{v},
      %|\func[_o]| = |\vec{v}| %
      %  \Rightarrow  %
      \isdet\ \prog\ {(\pred\ (\vec{t}\ \vec{v}))} \bigwedge \vecL{\semi{\funcF}\ t_i}                                                                                                                     \\
                                                                   & \mathrm{where\ } |\func[_o]| = |\vec{v}| \mathrm{\ and\ } \ctx\ \pred{} = \dtype{\detI}{\funcF}{(\funcF_o \  \func_o)} \vspace{0.5em} \\
      \semi{\dtype{\relI}{\_}{\_}}\ \prog\ (\predt) =              & \top                                                                                                                                  \\
    \end{array}
  $$
  % \endgroup
\end{definition}

The first equation states that if the preconditions of a signature are satisfied
then the call to a predicate of that signature is
functional and the post conditions on the outputs hold.
The contravariance of the \mySub test is reflected by the
fact that for any $t$, if $f_1 \mySub f_2$ then
$\sem{f_1} t \Rightarrow \sem{f_2} t$:
the post-conditions of $f_1$ can be stronger than the ones of $f_2$ while
the pre-conditions of $f_1$ must be weaker than the ones of $f_2$.

% We use the meaning of signatures to describe the key invariant of program:
\newcommand{\iprog}[1][\prog]{\ensuremath{\texttt{checked}\ \Gamma\ #1}\xspace}
\begin{definition}[Program invariant \iprog]\label{def:i}
  We say that \iprog{} holds iff for all predicates $\pred \in \prog$ s.t. $\ctx\ \pred = \dtype{\detI}{\_}{\_}$
  then  $\forall \vecL{t}, \sem{\detI}\ (\predt)$.
\end{definition}

Since the program can locally assert clauses we need
\checkc\ to preserve the invariant.

\begin{lemma}[Invariant preservation]
  % \vspace{-1em}
  $$\forall\, \Gamma\ \prog\ r\ v, \iprog \land \checkClause{\ctx}{r}{v} \Rightarrow \iprog[(\prog + r)]$$
  \label{th:0}
  \vspace{-1.5em}
\end{lemma}

\begin{proof}
  \color{red}%
  Without loss of generality, let $r = \clauseCmd{q}{\vecL{u}}{bs}$ be a clause
  for a predicate $q$, with a list of terms $\vecL{u}$ and a list of premises
  $bs$. Let $u_i$ (resp. $u_o$) denote the input (resp. output) terms in
  $\vecL{u}$ with respect to the mode annotations for $q$. We assume $\ctx\ q =
    \dtype{\detI}{\_}{\_}$.

  By definition of \checkc, we have the following:
  \begin{itemize}
    \item[H1:] $q\ \vecL{u}$ is mutually exclusive with all the rules in \prog.
    \item[H2:] $\fold\ \checkCmd{\ctx[']}{\detI}{\vecL{bs}}{\ctx['']}{\detI}$,
          where $\ctx'$ is the context in which the variables in $u_i$ are assumed
          to have the determinacy expected by the predicate's signature.
    \item[H3:] For any valid call to $q$ (i.e., where the inferred determinacy
          of its input arguments is weaker than or equal to that in $\func_i$), the
          output terms (under $\ctx['']$) must have determinacy weaker than or equal
          to that in $\func_o$.
  \end{itemize}

  By \cref{def:sem}, we need to prove that, given:
  \begin{itemize}
    \item[H4:] a deterministic predicate $p \in (\prog + r)$ such that $\ctx\
              {p} = \dtype{\detI}{\func_i}{\func_o}$,
    \item[H5:] a vector of terms $\vecL{t_i}$ such that $\vecL{\semi{\func_i}\
              t_i}$,
  \end{itemize}
  we have $\isdet\ (\prog + r)\ {(\predt)} \wedge \vecL{\semi{\func_o}\ (\prog +
      r)\ t_o}$.

      \noindent
  The second conjunct follows from H3 and H5.\\
  By \cref{def:is-det}, the first conjunct unfolds to:
  $$\forall a, \subst.\ \isDetCmd[\prog + r]{\predt}$$
  We proceed by induction on the trace obtained by running the query $\predt$ in
  the program $(\prog + r)$.

  If the trace is empty, we reach a contradiction, since the hypothesis requires
  that the program produces a result.

  If the trace is non-empty, suppose:
  $\texttt{trace}(\run\ (\varepsilon, [\prog + r, \predt, \varnothing])\ \varnothing) = x :: xs$
  We consider two cases:
  \begin{itemize}
    \item If $x \neq r$, then we apply the induction hypothesis to
          conclude.
    \item If $x = r$, then $xs = r :: b_1, \dots, b_n :: xs'$, where the $b_i$
          are the rules used to solve the premises of $r$.
  \end{itemize}

  Due to H1, $r$ is the only applicable rule for the original goal -- no other
  rule can be used to solve the current goal.\\

  Thus, the only potential sources of choice points are in the resolution of the
  premises in the body of $r$. By H2, each $b_i \in bs$ is an atom that either:
  \begin{itemize}
    \item does not introduce a choice point, or
    \item introduces a choice point that is cut away by a succeeding tail cut.
  \end{itemize}

  Finally, by the IH, all traces in $xs'$ are deterministic. This concludes the
  proof.

\end{proof}

As one expects a checked query evaluates deterministically under
a checked program.
% The main theorem states that a checked initial query behaves deterministically
% under a checked program.

\begin{theorem}[Deterministic execution]
  Given a context \ctx and an atom $t$, then
  $$\forall\, \Gamma\ \prog\ t, \iprog \land \checkCmd{\ctx}{\detI}{t}{\_}{\detI}
    \Rightarrow \isdet\ \prog\ t$$
  \label{th:1}
\end{theorem}

\vspace{-1.5em}
Since programs can be encoded into atoms (via the \elpiIn{=>} operator)
we can directly relate the static check with the deterministic execution of atoms.

\begin{corollary}[Static check entails Deterministic execution]
  % Given a context \ctx and an atom $t$, then
  % \vspace{-1em}
  $$\forall\, \Gamma\ t, \checkCmd[\EmptyList]{\ctx}{\detI}{t}{\_}{\detI}
    \Rightarrow \isdet\ \EmptyList\ t$$
  % \label{th:1}
\end{corollary}


% \noindent
% This theorem is crucial for establishing the connection between our determinacy
% checker and the a program execution. Specifically, if our \checkk\ procedure
% verifies that a given atom is \detI, we can guarantee that its interpretation
% will produce no choice points.

% The invariant we preserve in the proof is that \checkk\ ensures $\sem{\detI}\ t$
% while guaranteeing that all the input terms appearing in $t$ respect
% $\semi{\cdot}$.

% \Cref{th:1} can be generalized to work in a context where a concrete program
% \prog is provided (instead of having the initial empty program). This program is
% possible thanks to \cref{th:run-empty}. The program \prog is extracted thanks to
% the \atomtoprog\ function.

% The hypothesis in \cref{th:1} about the fact that local clauses for
% deterministic predicate should have a \cut can be relaxed in some situations.
% The interesting property allowing to remove \cut while respecting the semantics
% of the program is the so-called mutual-clause exclusion.

% \begin{lemma}[\mutExcl]
%   Given a program \(\prog\), it exists an equivalent program \(\prog'\) that
%   contains the minimal number of \cut\ operators. 
% \end{lemma}

% \def\remCut{\ensuremath{\mathcal{R}}}

% \begin{definition}[Remove redundant \cut (\remCut)]
%   Given a program \prog, we can build a program $\prog'$, which is a copy of
%   \prog where for each clause \( c = \clauseCmd{\pred}{\vec{t}}{\vecL{bs}, \cut,
%   \vecL{ds}} \) in \(\prog\), if all premises in \(\vecL{bs}\) are valid calls to
%   deterministic predicates and $\mutExclAll\ \prog\ c$, then
%   the \cut\ can be safely removed.
% \end{definition}

% Finally, we can generalize \cref{th:1} as follows.

% \begin{theorem}[Deterministic execution] \label{th:2}
%   Given a predicate context \ctx, a program \prog\ and a predicate \pred, s.t.
%   $\ctx\ \pred = \dtype{\detI}{\_}{\_}$, then
%   $$
%   \mutExclAll\ \ctx\ \prog \land
%   (\forall c \in \prog, \checkc\ \ctx\ c) \land
%   \checkk\ \ctx\ (\pred\ \vec{t})
%   \Rightarrow
%   \isdet\ \prog\ (\pred\ \vec{t})
%   $$
% \end{theorem}

% \begin{proof}
%   We can prove this final lemma thank to \cref{th:run-empty}, combining the

% \end{proof}
\vspace{-1em}
\paragraph{\textbf{Digression on \isdet}.}

In the logic programming literature, the notion of a ``function'' does not
necessarily align with the definition we adopt in \isdet. In particular, a
program that repeatedly produces the same result infinitely many times
undeniably represents a mathematical function. However, from a programmer's
perspective, such behavior is fundamentally different from that of a program
that terminates after producing a single result. Our definition %intentionally
captures the latter, as it better reflects the computational complexity of
programs %, particularly in cases of failure 
(as also observed by \cite{1989Vink}).

Consider the following \elpiIn{silly} predicate and two (alternative)
implementations of \elpiIn{mem}.

\begin{elpicode}
  ~   ~   pred mem i:A, i:list A.                    func mem A, list A -> .
  ~   ~   mem X [X|_].                               mem X [X|_] :- !.
  ~   ~   mem X [_|XS] :- mem X XS.                  mem X [_|XS] :- mem X XS.
  ~   ~
  ~   ~   func silly list int -> int.                func once (pred) -> .
  ~   ~   silly L V :- mem 1 L, len L V.             once P :- P, !.
\end{elpicode}

The signature of \elpiIn{silly} is accepted by our check only
if \elpiIn{mem} is functional in our sense (code on the right).
In this case the code of \elpiIn{silly} is operationally
equivalent to ``\elpiIn{once (mem 1 L), once (len L V)}'' where the worst-case
complexity is clearly the sum of its parts (and not its product).
Moreover we found that beginners are often confused by backtracking,
especially when they instrument their code for debugging:
we believe our static check for \emph{observational} determinacy can mitigate that.

\paragraph{\textbf{Digression on  the eagherness of $\mathcal{H}$}}
\label{sec:digression-h}

The function $\mathcal{H}$ in the operational semantics (Figure~\ref{fig:basic-interp})
eagerly unifies all clauses with the goal.
A more natural and possibly more efficient semantics would be to just create the
alternatives and prepend to the list of goals the same matching/unification
problems, but that would not satisfy \isdet.

From a practical standpoint an efficient implementation %of that semantics
can make $\mathcal{H}$ lazy without compromising the \isdet property
if either it indexes clauses deep enough
or it transforms the program by inserting
\elpiIn{once} around each call to a deterministic predicate.
