\section{Determinacy analysis for Horn Clauses with cut}
\label{sec:basic}

% Before providing a formal definition of determinacy and mode analysis, we
% first describe the language we are working with, namely a dialect of \lamprolog
% called \elpi.

% Since we have structured our paper into two main sections: 1) the first
% discusses a basic version of \elpi with only Horn clauses and the cut operator,
% and 2) the second extends this version by introducing hereditary-Harrop
% formulas. Below we give a simple presentation of some basic 
% objects of our language, they will be expanded in next section when needed.
% \\

\subsection{Syntax}

\begin{minipage}{0.45\textwidth}%
  \vspace{-1em}
  \begin{align}
    tm     & ::= \cut \mid \predVar\ \vecL{tm} \mid tm = tm \label{eq:tm} \\
    ty     & ::= data \mid \texttt{pred}\ data\ast \label{eq:ty} \\
    data   & ::= \texttt{c}\ data^\ast \mid \predVar \label{eq:data}
  \end{align}  
\end{minipage}
\begin{minipage}{0.45\textwidth}
  \vspace{-1em}
  \begin{align}
    clause & ::= \clauseCmd{\pred}{\vecL{tm}}{\vecL{tm}}                  \label{eq:cl}  \\
    goal   & ::= \goalCmd{\prog}{tm}{\vecL{alt}} \label{eq:goal}                            \\
    alt    & ::= \texttt{subst} * \vecL{goal} \label{eq:alt}
  \end{align}  
\end{minipage}

Terms are shown in \cref{eq:tm}. They are made by the \cut\ operator
(usually noted \elpiIn{!}); term application, we use the symbol \predVar\
to indicate variable names, they can be either predicate names, i.e. constants
of the program, or quantified variables. An application is followed by a
vector of terms. Term unification is a special case of term application,
we prefer to have a special case for it. 
By convention we differentiate unification variables from constants
by indicating the former with capital letters and the latters
with lower case letters.



Each term in the language has a type (\cref{eq:ty}). The type is either a
$data$, that is the type of expressions or a $pred$ the type for predicates,
that is the type of executable piece of code. Predicates are parametrized by
arguments whose type are of type $data$. $data$ (\cref{eq:data}) are made by
constants applied to list of data, we have for example the type \elpiIn{int} or
\elpiIn{list}, and \predVar\ stands for variables, allowing therefore to have
polymorphism.

A clause (\cref{eq:cl}) is made of a variable name, its list of arguments and a body made of a
list of terms. This list of terms are called \textit{premises} and should be
considered as a list of subgoals in conjunction.

\subsection{Dynamic semantics}

A program \prog is a mapping from predicate names to clauses. These clauses are
disjunctive, and the order in which they are explored follows the chronological
order of their declaration.
In our approach, we do not include built-in operators, keeping the language as
minimalist as possible. For instance, there is no built-in \textit{or} operator.
However, its behavior can be replicated by defining a custom \textit{or}
predicate with two arguments and providing two implementations: one invoking the
first argument and the other invoking the second.

% A program is a mapping from predicate names to clauses. By hypothesis, we assume
% that every program we work with from now on has been type-checked (see
% \cite{1992nadathur}). One of the role of type-checking is to ensure that
% commands and expressions are not mixed: commands, also called propositions, are
% pieces of executable code, whereas expressions are not. Instead, expressions
% serve to carry pieces of information during the execution of commands.

A goal (\cref{eq:goal}) is a triple made of a program \prog, a term
and the list of alternatives \alt existing at moment of the creation of
the goal. A query is a list of goals (noted \g in the following) in conjunction, whereas alternatives
(\cref{eq:alt}, noted \alt in the following) represent a disjunction of goals.
% In particular,
% \g is evaluated by looking into the clauses inside \prog.
% \alt
% contains the choice-points used by the interpreter during the evaluation of a
% cut, the aim of this piece of data will be clarified further in the section
% dedicated to the interpreter implementation (see \cref{sec:basic-elpi}).

The interpreter takes a program a query and returns a substitution if the query
is a consequence of the program. Each time a predicate call has multiple clauses
implementing it, it commits the first choice and keep the other as global
alternatives. If the committed choice leads to a failure, the interpreter will try to
execute the first alternative. This non-deterministic behavior can be controlled
by the user thanks to the cut operator which allows to cut away unwanted choice
points.

We say that a clause applies on the goal if its head unifies with a goal
and we say that it \textit{successfully} unifies with a goal if the clause
applies on the goal and all premises in its body succeed.

% \begin{coqcode}
%   Definition pn := string. (*predicate names are strings*)
%   Definition vn := string. (*variable  names are strings*)
%   Inductive tm := 
%     | Call (p:pn) (i:tm) (o:tm)  (*binary predicates taking integers*)
%     | Cut                        (*the cut operator*)
%     | Unify (t1:tm) (t2:tm)      (*unification between t1 and t2*)
%     | Var (n:vname)              (*a variable*)
%     | Lam (x: vn) (b:tm)         (*lam abstraction*)
%     ...                          (*this is extended in section XX*)
%   Inductive clause := Clause (p:pn) (i:tm) (i:tm) (A:list tm).
%   Notation "P I O :- Bo" := (Clause P I O Bo).
%   Notation "t1 = t2" := (Unify t1 t2).
%   Definition sbst := T.
%   Definition prog := pn -> list clause.
%   Inductive goal := Goal (P:prog) (a:tm) (A:list alt) -> goal.
%   with alt := sbst * list goal.
% \end{coqcode}

The evaluation of a program is done through the \run\ predicate. It is a
function with the following signature:
%
$$run : goal \to \vecL{alt} \to subst \to (\vecL{alt} * subst)$$
%
% \begin{minted}[autogobble]{coq}
%   Inductive run : goal -> list alt -> subst -> list alt -> subst := ...
% \end{minted}

\coqIn{run} should be understood as a relation between a goal \g, a list of
alternatives \alt (which are disjunctive with the current goal), and an initial
substitution \subst. These three components produce a new list of alternatives
\alt['] and an updated substitution \subst['].
The notation \runCmd{\mathcal{G}}{\mathcal{A}}{\subst}{\mathcal{A}'}{\subst'}
represents calls to \run. The corresponding system of rules is presented in
\cref{fig:basic-interp}.
\begin{figure}

  \ruleStopM{.45}
  \ruleFailM{.45}
  \vspace{0.3em}%

  \ruleUnifM{.50}
  \ruleBangM{.40}
  \vspace{0.3em}%

  \ruleCallM{1}

  \caption{Dynamic semantics}
  \label{fig:basic-interp}
\end{figure}


% The idea is that the intepreter stops
% when it finds the first solution, which is a valid substitutions for the query
% wrt the program. In order to find all the solution of query from the current
% program, that is all the valid substutions for the query, it is sufficient to
% iterate over all the alternatives \alt['].

% In the following we use the following notation for call to the run predicate:
% %
% $$ \runCmd{\mathcal{G}}{\mathcal{A}}{\subst}{\mathcal{A}'}{\subst'} $$
% In this first section we start with a first-order version of a logic language.

It is an operational semantics similar to \cite{1990Vink}, where rules represent
the evolution from one configuration (below the line) to the next (above the
line). The choice to use operational semantics rather than denotational
semantics (as in \cite{2011king}) stems from our preference for maintaining a
concrete representation of the objects we manipulate. Instead of using
continuations to store the state of a choice point, we represent this
information as lists containing the alternatives, along with the substitution
that existed at the moment the choice point was created.

In the derivation
system, we use the two-colon symbol ($::$) as separator between the head of a
list and its tail; $@$ stands for list concatenation; $\EmptyList$ is the empty list.
``$\prog\ \pred$'' is the application of \prog to the predicate \pred; it returns the list of
clauses for \pred\ in the program. The function $\mathcal{F}$ is defined as follows:
%
$$
  \mathcal{F}(\prog, \pred, \vec{t}, \subst, \alt) :=
  \Bigg[\bigg(\subst,
    \Big(
    \big[(\prog, \vec{t}_x = \vec{u}_x, \alt) \mid x \in \text{len }t\big] @
    \big[(\prog, g, \alt) \mid g \in bs\big]
    \Big)\bigg) \mid \clauseCmd{\pred}{\vec{u}}{bs} \in \prog\ \pred\Bigg]
$$

It takes program \prog, a predicate name \pred, a list of terms,
a substitution $\subst$ and a list of alternatives \alt. For each clause
\clauseCmd{p}{\vec{t'}}{bs}, it builds a new list of pairs where the first argument
is the substitution $\subst$ and the second is the list of new goals to treat.
This list is made by all the unification between the terms received at call
time and the argument of the clause and is followd by the premises
of the clause that have been transformed in a goal.

The behaviour of the \run\ procedure depends on the shape of the list of goal and its
alternatives. A query succeed if it exists a sequence of reductions allowing to reach the
\textit{stop rule}, symbolyzed with \ref{rule:stop}.

More precisely, the \textit{stop rule} captures configurations with an empty
list of goals. By convention, this configuration is final: there are no more
goals to process, so we stop and return the same alternatives and substitution
received as input.

The \textit{fail rule} (\ref{rule:fail}) consumes the list of alternatives if the
first goal fails. A failure occurs if the goal at the head of the list is a call
to a predicate with no clauses in the associated program or if it is a
failing unification under the given substitution.
% In fact, this
% rule allows to break loop since it can non-determinalistically applied on any
% configuration, provided that the list of alternatives is not empty. It is
% possible to make the algorithm deterministic by chainging \ruleFail so that it
% is applied if the current goal is a call to a predicate with no alternatives,
% but we prefer to simplify our rule system.

The \textit{unify rule} (\ref{rule:unif}) is applied when a unification $t_1 = t_2$
appears at the head of the current goal list. It invokes the \unify algorithm on
the two terms $t_1$ and $t_2$ using the substitution \subst and returns the
updated substitution \subst[']. Finally, if the unification succeeds, the \run\
procedure is called with the list of remaining goals \g and the new substitution
\subst['].

A variable is a term not yet instantiated. We can assign variables thanks to the
\unify\ procedure. It is used each time a term like $t_1 = t_2$ is encountered
while solving a goal. The notation \unifyCmd{t_1}{t_2}{\subst}{\subst[']} is
the unification and between the terms $t_1$ and $t_2$. It also takes an initial substitution \subst
which is updated into the final substition \subst[']. A substitution is a mapping from variables name to their
assignment. An assignment is a term. Unification provides, when possible, a most general unifier
between the two terms. The notation $\subst t$ is the application of a substitution
to a term.
It returns a new term where all the variables in $t$ have been recursively
replaced by heir assignment in \subst. If the variable as no assignment
in \subst\ then the same variable is returned.

Unification has some interesting properties

\begin{definition}[Unification negation]
  \vspace{-1em}\todo{qui = è il same term}
  $$(\forall \subst, \lnot (\exists \subst['], \unifyCmd{t_1}{t_2}{\subst}{\subst[']}) \to (\neg (\exists t_3~\subst_1~\subst_2,
      \subst_1 t_1 = \subst_1 t_3 \land \subst_2 t_2 = \subst_2 t_3))$$
\end{definition}

\begin{definition}[Substitution union]
  \vspace{-1em}\todo{qui = è il same term}
  $$\subst_1 \cap \subst_2  = \varnothing \to \subst_1\ t_1 = \subst_2\ t_2 \to (\subst_1 \cup \subst_2)\ t_1 = (\subst_1 \cup \subst_2)\ t_2$$
\end{definition}


The \textit{cut rule} (\ref{rule:cut}) refers to goals where the first goal has the
\cut as atom. Since in our implementation we use the \textit{hard-cut} operator,
we proceed in solving the list of remaining goals but the alternatives we keep
are the one stored in the goal. This alternatives are called cut-alternatives.
As said in \cite{2003Andrews}, (hard-)cut is a non-logical operator ``cutting
away not only the later clauses of the same predicate, but also the alternative
clauses for subgoals that appear earlier in the clause''.

The \textit{call rule} (\ref{rule:call}) deals with goals starting with a predicate
call, \pred\ is the notation to represent predicate name. In this case the function $\mathcal{F}$ is called with the parameters as
explained above and if the result of this operation is the list
\ConsHd{b}\ConsTl{bs}, then a recursive call to \run\ is done by prepending $b$ to
the list of remaining goals \g and $bs$ is prepended to the list of
alternatives \alt.

The combination of the \ref{rule:call} and \ref{rule:cut} rules is crucial for replicating
the behavior of the cut. When a call to a predicate generates multiple rules as
new choice points, the function $\mathcal{F}$ creates future disjunctive goals
where the cut alternatives are set to the current list of alternatives \alt. In
other words, if the alternatives before reaching a call to a predicate \pred are
\alt and \prog is the current program, then if ``\prog \pred'' results in
clauses $c_0, \dots, c_n$, any clause $c_j$ with $i < j \leq n$ will be
discarded if clause $c_i$ contains a cut. Furthermore, if the body of $c_i$
consists of the atoms $a_1, \dots, a_k, !, a_{k+2}, \dots, a_m$, then all choice
points created during the evaluation of $a_1, \dots, a_k$ will also be pruned.
This pruning consist simply in setting the cut alternatives to \alt.

As an example, let's consider the following program called \prog:

\begin{elpicode}
  p1 X Y :- p2 X Y.           % r1
  p1 3 3.                     % r2
  p2 X Y :- p3 X Y, !, Y = 1. % r3
  p2 1 1.                     % r4
  p3 1 2.                     % r5
\end{elpicode}

{
\def\goalG{\goalCmd{\prog}{\callCmd{\texttt{p1}}{3\ Z}}{\EmptyList}}

Let $\mathcal{G} :=\ \goalG$ be a goal, the execution of
``\runCmd{\mathcal{G}}{\EmptyList}{\EmptySubst}{?A}{?\subst}'' will apply \ref{rule:call}
producing a new goal for the rule $r1$ and an alternative list containing $r2$,
we leave out details concerning unifications of head terms. The execution of
$r1$ will try to solve $r3$. This will add three goals \elpiIn{r 1 Y, !, Y = 1}
with cut-alternatives equal to $r2$ whereas the new alternatives will be $r4 @
  r2$. The execution of $r3$ will solve \elpiIn{p3 1 Y} with substitution $s :=
  \{X \gets 1; Y \gets 2\}$. The \elpiIn{!} will cut away the alternative $r4 @
  r2$ and will keep the cut-alternative $r2$. The failing premise \elpiIn{Y = 1}
will cause a backtracking thanks to \ref{rule:fail} and try to apply $r2$ from the
empty substitution. This last unification succeed with final substution $?\subst :=
  \{X \gets 3; Y \gets 3\}$ and final list of alternatives $?A := \EmptyList$.

% \begin{myRule}{1}
%   \AxiomC{}
%   \RightLabelM{\ruleCall}
%   \UnaryInfC{\runCmd{\mathcal{G}}{\EmptyList}{\EmptySubst}{?A}{?S}}
% \end{myRule}

}

% \subsection{The cut operator}
% \label{sec:cut}

% Logic programs are known for their non-deterministic behavior: there can be
% multiple distinct ways to derive a query from a knowledge base, and logic
% programs aim to find all of these solutions. While non-determinism is a key
% feature, it is sometimes important to allow the user to control if and when
% alternatives should be rejected. The cut operator is designed to address this
% problem.

% Since we use the elpi dialect of \lamprolog, it is important to clarify how
% the cut behaves in our development. It is that case that each prolog-ish language
% has its own cut implementation, for example in the official page of
% swi-prolog (\href{www.swi-prolog.org}{www.swi-prolog.org}) we see that
% there are two different cut implementations: the \textit{soft cut} noted with
% ``\texttt{C *-> T ; E}'' runs E if C has no solution otherwise the result is the
% same as running the conjunction of C and T. The \textit{hard cut} noted with the
% ``\texttt{!}'', "discards all choice points created since entering the predicate
% in which the cut appears".

% The \mercury system \cite{1996Somogy} is meant to be a pure programming language
% extended with types, modes, determinism and module systems. In order to satisfy
% its purity, \Mercury only accepts a version of the soft cut.

% It is also interesting to see that further representations of cut may exists,
% such as the firm cut explained in \cite{2003Andrews} where they provide a
% restricted version of the hard cut which has some concistency properties.

% \Elpi implementation uses the hard cut definition. Even though the hard cut have
% no equivalent representation from pure logic, we are convinced that, from a
% programming perspective, it is quite practical. It allows us to eliminate not
% only alternative implementations of a predicate but also to prevent backtracking
% of all choice points born from the begin of the clause-body to the current cut
% position.

% For example, in \elpi, the \textit{if-then-else} construct, which is not a\todo{wrong if pred are bin + no prop as arg}
% primitive of the language, can be impelented as follows:
% \begin{elpicode}
%   if C T E :- C, !, T. % if1
%   if _ _ E :- E.       % if2
% \end{elpicode}
% Due to the hard cut, the query ``\elpiIn{if C T E}'' executes the \texttt{if1} rule.
% If \elpiIn{C} has $n > 0$ solutions then only the first is kept, the other being
% cut away as the rule \texttt{if2}. The call then succeeds only if \elpiIn{T} has
% a solution. The rule \texttt{if2} will be run only if \elpiIn{C} has no
% solution.

% For example, in the following database:

% \begin{elpicode}
%   p 1.
%   p 2.
%   q 2.
% \end{elpicode}
% The query ``\elpiIn{if (p X) (q X) (0 = 1)}'' fails. Note that the usage of the
% soft-cut would make the same query to have a solution, since the backtracking in
% the condition would be authorized.
% \todo{cut di teyjus}

\subsection{Static analysis: modes}
\label{sec:modes}

Before talking about determinacy and the impact that hard-cut has on it. We
prefer to spend some few words about the definition of modes, because as
explained in \cite{1989Warren,1996Somogy} modes are the basis for determinim.

The general idea is that a logic program allows to express relations, but,
sometimes it is also needed to express \textit{directed} relations, where arguments are
differenciated between inputs and output. Said in an other way, output arguments
can be derived from input arguments. It is often the case that the user of a
logic programming langauge tend, in most of cases, to express directed
predicates. The typical example of this need is the \texttt{append} predicate
aiming to concatate two lists.

In a prolog-ish program without modes, the following program:

\begin{elpicode}
  append [X|Xs] L [X|L'] :- append Xs L L'. % app1
  append [] L L.                            % app2
\end{elpicode}

\noindent
makes the query ``\elpiIn{append Y [] L, 0 = 1}'' to diverge.
Here the variable \elpiIn{Y} is unified with a list of infinite
length, the rule \texttt{app1} being continously applied.

Modes are there to avoid this situation. The most widespread mode definition
in the literature are two: the input
mode and the output mode. The idea is that each predicate is annotated with a
mode signature, and a static mode checker verifies that the clauses of the
program are consistent with the mode declrations of the predicates. Essentially,
in the head of a clause, 1) terms appearing in input position are supposed to be
ground whereas 2) terms in output position must become ground in the body of the
clause. Within each premise of the body, 3) terms appering in output positions become
ground while 4) terms appearing in input positions are checked to be ground. If
condition 2) or 4) are not satisfied a mode compilation error is raised.

\begin{definition}[Well-moded program (\wellModed)]
  Given a program \prog, for any clause $c$ in \prog, we say that \prog\
  is well moded if it respect the informal description we have given above
  % TODO: da rifare
  % \begin{coqcode}
  %   Definition ~\customlabel{wellmoded}{\texttt{well\_moded}}~ ~\prog\!\!~:
  %   forall p i o (HG: ground i) ~\subst \subst[']~,
  %   (H: ~\runCmd{[\goalCmd{\prog}{\callCmd{\texttt{p}}{\texttt{i}\ \texttt{o}}}{\EmptyList}]}{\EmptyList}{\subst}{a}{\subst[']}~),
  %   ground (~\subst' ~o).
  % \end{coqcode}
  \label{def:well-moded}
\end{definition}

In \twelf \cite{1996pfenning}, which is an implementation of \lamprolog, mode
checking is extended to work with local nominal variables and higher-order
variable unification within the pattern fragment.

% The definition above can be rephrased as follows: a program \prog is well moded
% if for any (binary in our setup) predicate \pred called with a ground input
% \texttt{i} and any output term \texttt{o}, if the call succeeds producing a
% substitution \subst['] then the application of that substitution to \texttt{o}
% is a ground term.

It is interesting to note that mode checking under the groundness condition is
sometime too restrictive. In some situation it is in fact sufficient to work
with term that are "enough" ground to guarantee the wanted properties. As an
example, both \cite{1994apt-oc} and \cite{2002overton}, even though they
researches concern different areas, present a version of this mode checking with
"enough" instantiated terms together with some condition of variable linearty.

In our paper, we will combine these ideas. In particular,
since \elpi is used as a
meta-language for proof verification
\cite{tassi2018,tassi2019,tassi2023,fissore2023,fissore2024}, we
need to work with a higher-order setup where inputs (and outputs) may not be
fully instantiated: the role of the search engine is to potentially assign
unification variables. In the first part of the paper, we will introduce the
seamantics of the input mode which is used in \elpi.
In the second part, we extend it so that it works with predicates taking
predicate calls as arguments.

\subsection{Static analysis: functionality}
\label{sec:det}


Determinacy, as previously mentioned, is the property of a predicate that
returns at most one solution per call. Such a predicate behaves like a function,
which is why we refer to it as a deterministic predicate or simply a function.
Determinism checking statically ensures that the clauses implementing a
deterministic predicate adhere to this condition. The literature contains
numerous discussions on this topic, offering various descriptions and
applications of determinism.

In \cite{1989Warren}, the authors describe a property subsuming
determinism: they describe functionality. A predicate is
functional if it produces at most one \textit{distinct} solution per predicate
call. The keyword here is \textit{distinct}, since, in the determinacy setting,
a predicate call producing the same solution twice is not considered as
deterministic, while, it is functional. %In the paper they explain that mutual
% exclusivness of clauses can be improved not only by looking at the head and at
% the presence of the cut but also by instructing the checker that premises can
% put clauses in mutual exclusivness.

In \cite{1991Sahlin}, and more formally in \cite{1996mogensen}, determinacy is
used to work with \mixtus, a partial evaluator of \prolog. In that case,
determinacy is inferred so that it is possible to derive a new specialiezed,
and therefore more efficient, version of the original program under the
guarantee that the two program share the same semantics.

Finally, in \cite{1996henderson}, a determinacy checker for \mercury
captures different behaviours of a predicate. A predicate can return
exactly zero and/or one solution, zero and/or multiple solution. In \mercury the
user is allowed to annotate predicates with determinacy information. A
non-annotated predicate will be inferred with the lowest derived tag.
Determinacy, in \mercury, besides giving a guarantee on the program, allows to
specialized it so that a faster routine can be used in the compiled program.

The following notation helps us to capture the definition of determinacy.

\begin{definition}[Deterministacy (\isdet)]
  Given a program \prog and a term $t$,
  \isdet\ is defined as follows:
  $$\forall a\ \subst, \isDetCmd{t}$$
  \label{def:is-det}
\end{definition}

The determinacy definition that adhere the most to our need is the one
considering the arguments marked as input as terms that are consumed by the
interpreter and that allow to produce determinalistically the output. %In order
% to differenciate input from output in an application like $\predVar\ \vec{t}$,
% we use the notation $t_i$ and $t_o$ to respectively separate the input and the
% output arguments of \predVar.

In order to differenciate relations from deterministic predicates, and also
to distinguish input from output arguments, we change the signature of predicate
as follows:
%
\begin{align}
  pred ::= [\detI \mid \relI]\ data^\ast \funsep data^\ast
  \label{eq:pred}
\end{align}

A predicate is either deterministic (\detI) or relational (\relI). The symbol
\funsep\ separates input from output arguments. We let \expI\ be a shortcut for
for all terms of type $data$ and let \ctx\ be a mapping from predicate names to
their determinacy type (dtype). For now, the dtype is simply the type of the
predicate where all $data$ have been replaced with \expI. For example, if
\elpiIn{succ} is a function two arguments of type \elpiIn{int} the first being
the input the second being the output, then ``$\ctx\ \texttt{succ} =
\dtype{\detI}{[\expI]}{[\expI]}$''. By convention we say that in a predicate
signature all inputs comes before outputs.

We resume below the definitions and the properties
that are needed for determinacy checking.
%
% Under the hypothesis to work
% with program statically mode-checked, a necessary condition for a
% predicate to be deterministic is that no two clauses can be applied successfully
% on the same predicate call. Two clauses respecting this property are called
% mutually-exclusive.
%
To define this property, we first need to introduce some the auxiliary
definitions.


\begin{definition}[Mutually-exclusive heads (\mutExclHeads)]
  % \begin{coqcode}
  %   Definition ~\customlabel{mutexcl}{\texttt{mutual\_exclusive}}\prog \pred\!\!~:
  %     ~$\forall\ i1\ o1\ bo1\ i2\ o2\ bo2$~ (H1: ~\clauseCmd{p}{i1\ o1}{bo1}~ \in ~$\prog\ p$~) (H2: ~\clauseCmd{p}{i2\ o2}{bo2}~ \in ~$\prog\ p$~),
  %         not (exists ~\subst\!\!~, ~\unifyCmd{i1}{i2}{\EmptySubst}{\subst}~)
  % \end{coqcode}
  Given a context \ctx\ and two clauses
  $c_1 = \clauseCmd{\pred}{\vec{t}}{bo_1}$ and
  $c_2 = \clauseCmd{\pred}{\vec{u}}{bo_2}$. Let $\ctx\ \pred = \dtype{\_}{i}{\_}$
  and $k$ being the length of $i$, then
  \begin{align*}
    \forall \subst \exists n, 0 \leq n < k \land \lnot (\exists \subst['], \unifyCmd{\vec{t}_n}{\vec{u}_n}{\subst}{\subst[']})
  \end{align*}
  \vspace{-2em}
  \label{def:mut-excl-head}
\end{definition}

That is, two clauses have mutually-exclusive heads if it does exists a
term in input position discriminating them, the subscript $n$ in the
formula retrives the $n^{th}$ argument in a vector of terms.

\begin{lemma}[Mutually-exclusive heads property]
  Given a context \ctx and two clauses $c_1 = \clauseCmd{\predVar}{\vec{t}}{b_1}$ and $c_2 = \clauseCmd{\predVar}{\vec{u}}{b_2}$ then
  let $\vec{t}_i$ and $\vec{u}_i$ the inputs arguments of $\vec{t}$ and $\vec u$ respectively.
  % forall vector of \textit{ground} terms $\vec{v}$,
  $$\mutExclHeads\ \ctx\ c_1\ c_2 \to \forall \subst_1\ \subst_2, \lnot (\exists \vec{v},
    \vecL{\ground\ v} \to \unifyCmd[1]{v}{t_i}{\EmptySubst}{\subst_1} \land
    \unifyCmd[1]{v}{u_i}{\EmptySubst}{\subst_2})$$
  \vspace{-2em}
  \label{th:mut-excl-head}
\end{lemma}

\begin{proof}
  By contradiction, let $\vec{v}$ be a ground vector unifying with both $\vec{t}_i$ and $\vec{u}_i$. This
  means that there exists two substitutions such that $\subst_1\ \vec{v} = \subst_1\
    \vec{t}_i$ and $\subst_2\ \vec{v} = \subst_2\ \vec{u}_i$. Since $\vec{v}$ is ground the equations can be
  simplified into: $\vec{v} = \subst_1\ \vec{t}_i$ and $\vec{v} = \subst_2\ \vec{u}_i$, implying that
  $\subst_1\ \vec{t}_i = \subst_2\ \vec{u}_i$. However, due to $\mutExclHeads\ \ctx\ c_1\ c_2$,
  $\vec{t}_i$ and $\vec{u}_i$ cannot be unified: for any substituions
  $\subst[']_1$ and $\subst[']_2$, we have $\subst[']_1\ \vec{t}_i \neq \subst[']_2\
    \vec{u}_i$, a contradiction.
\end{proof}

% \begin{coqcode}
%   Definition mutual_exclusive_head '(p i _ :- _) '(p i' _ :- _) :=
%     not (exists ~\subst\!\!~, ~\unifyCmd{i1}{i2}{\EmptySubst}{\subst}~)

%   Definition mutual_exclusive_cut c1 c2 :=
%     before c1 c2 -> with_cut c1

%   Definition mutual_exclusive prog p :=
%     forall c1 c2, c1 <> c2 -> c1 \in prog p -> c2 \in prog p ->
%       mutual_exclusive_clause c1 c2 \/ mutual_exclusive_cut c1 c2

% \end{coqcode}


\begin{definition}[Mutual-exclusion with \cut\ (\mutExclCut)]
  Given two clauses
  $c_1$ and $c_2$ such that $c_1$ is defined before $c_2$,
  the body of $c_1$ contains a \cut.
  \label{def:mut-excl+cut}
\end{definition}

\begin{lemma}[Mutually-exclusive \cut\ property]
  Given two clauses $c_1$ and $c_2$, if $\mutExclCut\ c_1\ c_2$, then
  $c_1$ and $c_2$ cannot be both applied simultaneously on the same goal.
  \label{th:mut-excl+cut}
\end{lemma}

\begin{proof}
  By induction on the derivation rules (\cref{fig:basic-interp}). The interesting case is the rule
  \ref{rule:call} when the heads $c_1$ and $c_2$ unify both with the current goal. If
  this is the case, then two cases should be taken into account: 1) the \cut\
  inside the body of $c_1$ is reached while running the program. In this case
  the \cut, will cut away the clause $c_2$ since, by contruction, it cannot
  appear in the cut-alternatives. 2) The \cut\ is not reached, that is, a failure
  occurs before reaching it. This means that the clause $c_1$ is not applied on
  the goal. In both cases both clauses cannot be applied simultaneously on the
  same goal.
\end{proof}

\begin{definition}[Mutual-exclusion (\mutExcl)]
  Given a context \ctx and a program \prog, forall predicate \pred, such
  that $\ctx\ \pred = \dtype{\detI}{\_}{\_}$ and
  for any two pair of clauses $c_1$ and $c_2$ in \prog\ \pred, then
  \vspace{-0.5em}
  $$\mutExclHeads\ \ctx\ c_1\ c_2 \lor \mutExclCut\ c_1\ c_2$$
  \vspace{-2em}
  \label{def:mut-excl}
\end{definition}

\begin{lemma}[Mutually-exclusion property]
  Given a context \ctx\ and a program \prog, if $\mutExcl\ \ctx\ \prog$ then for
  any call $\pred\ \vec{t}$ with ground inputs, it exists at most one clause that can be
  successfully applied on $\pred\ \vec{t}$.
  \label{th:mut-excl}
\end{lemma}

\begin{proof}
  By \cref{th:mut-excl-head,th:mut-excl+cut}
\end{proof}

The second important condition
for determinacy is the following:

\newcommand{\detAtom}{\texttt{det\_call}}

\begin{definition}[Deterministic term application (\detAtom)]
  Given a context \ctx\, the term $\pred\ \vec{t}$ is a deterministic
  call if $\ctx\ \pred = \dtype{\detI}{\_}{\_}$
\end{definition}

\begin{definition}[Deterministic premises (\detPrem)]
  Given a context \ctx\ and a program \prog, forall predicate \pred, such that
  $\ctx\ \pred = \dtype{\detI}{\_}{\_}$ and forall clause
  $(\clauseCmd{\pred}{\vec{t}}{b_1\dots b_n}) \in \prog\ \pred$,
  $$(\exists j, b_j = \cut \land \forall k, k > j \to \detAtom\ b_k) \lor (\forall j, \detAtom\ b_j)$$
  \vspace{-2em}
  \label{def:det-prem}
\end{definition}

This amout to say that in program \prog, a predicate \pred has deterministic
premises if the bodies of all its clauses either 1) have a \cut\ followed by
calls to deterministic predicates or 2) have only calls call to deterministic
predicates.

% \begin{lemma}[Deterministic premises property]
%   Let \prog and \pred be a program
%   $$\forall c, \prog\ \pred = [c] \to \wellModed\ \prog \to \runCmd{[\goalCmd{\prog}{\callCmd{p}{i}{o}}{\EmptyList}]}{\EmptyList}{\EmptySubst}{a}{\subst}, a = \EmptyList$$
%   \label{th:det-prem}
% \end{lemma}
% \begin{proof}
%   By induction on the derivation in \cref{fig:basic-interp}. The interesting
%   case is the \ruleCall. Since, by hypothesis, it exists only one clause $c$
%   implementing \pred in \prog, the recursive call has a new fresh list of goals
%   \g to treat (the premises $c$) and no choice points. Note that, by the
%   definition of the $\mathcal{F}$ function, all goal in \g has the empty list as
%   cut-alternatives. Two cases should be taken into account. 1) \g has a \cut.
%   Reaching the \cut\ will cut away all choice points which are set again to the
%   \empty list. After the \cut, all premises are call to deterministic
%   predicates. By induction hypothesis, this premises generates no choice points,
%   therefore the returned list of alternatives is the empty list, as expected. 2)
%   there is not \cut in \g, similarly to the previous case, all premises are call
%   to deterministic predicate, therefore we can conclude the proof using the
%   induction hypothesis.
% \end{proof}

\begin{definition}[Determinacy checking (\detCheck)]
  Given a context $\ctx$ and a program \prog,
  $$\mutExcl\ \ctx\ \prog \land \detPrem\ \ctx\ \prog$$
  \label{def:det-check}
\end{definition}

\begin{definition}[\ensuremath{\prog[^!]}]
TODO: add neck cut after all rules that do not have cut already
\end{definition}



\begin{elpicode}
p 1 3.
p 2 3.
% faccio call p T con T ground, ho una alternativa. ma so che
% fallirà perche 1 e 2 non unificano in met excl. Quindi P!
p 1 3 :- !.
p 2 3.
\end{elpicode}

\begin{theorem}[P! = P]
  run P iff run P!
\end{theorem}

\begin{theorem}[Determinacy checking property]
  Given a contxt \ctx and a program \prog, forall predicate \pred, such that
  $\ctx\ \pred = \dtype{\detI}{\_}{\_}$ then
  $$\wellModed\ \prog \to \detCheck\ \ctx\ \prog \to \forall \vec{t}, \vecL{\ground\ t_i}\ \to \isdet\ \prog[^!]\ (\pred\ \vec{t})$$
  \vspace{-20pt}
  \label{th:det}
\end{theorem}

\begin{proof}
  We can reason by induction on the derivations in \cref{fig:basic-interp}. The
  interesting case is the \ref{rule:call}. Due to \detCheck\ \prog, we know, by
  \cref{th:mut-excl} that at most one clause $c$ successfully applies on the
  call to \pred. By definition of $\mathcal{F}$\todo{there are also unif}, the new goals \g are made from
  the term in the body of $c$ and all of them will have by construction the empty list as
  cut-alternatives. We need to treat two cases. 1) \g has a cut. If all the
  goals before the \cut\ succeed, then all the choice points generated are cut
  away. Moreover, since, by hypothesis, all the goals after the \cut\ are calls
  to deterministic predicates, and since, \wellModed\ \prog,
  we know that all of these calls have at most one solution.
  We can now use the induction hypothesis on the remaining goals
  claiming that in the end the empty list of alternatives is produced,
  completing the proof for this case. 2) \g has not cut. The proof is similar
  to the previous one after having reached the cut.
\end{proof}

Several works \cite{king2005, king2006, 2011king} have been pursued
in order to build an inference model for determinacy in \prolog system with \cut.
Moreover, they explain that determinacy inference subsume determinacy checking.
Even though this last claim, we think that an inference model does not fit
well with our language.

The first motivation is that since \elpi is an interpreted dialect of \lamprolog,
program can change dynamically on the run of a program. This means that
rules can be added \textit{à la volée} making impossible to infer
determinacy as the user expects.
It's
up to the user to choose what should be the behavior of a predicate wrt
determinacy. The checker is meant to assist the user by rejecting, a predicate,
that does not respect the declared determinacy.

As explained in some of the previously cited papers, determinacy (and so
functionality) checking is an undecidable problem. The checking property is
sound: if a predicate passes the analysis then it is for sure deterministic.
However, it is not complete: there could exists false negatives. We are
convinced, that completeness, is not a big deal, since, as also claimed in ...
every deterministic predicate not passing the determinacy check,
can be rewritten in a equivalent way
so that it is no more classified as non-deterministic.

% \begin{coqcode}
% Definition ~\customlabel{detpred}{\texttt{det\_pred}}~(~\prog~: prog) (p: pn) :=
%   forall ~$i$~ ~$o$~ ~$a$~ ~\subst~(HG: ground i) 
%     (H : ~\runCmd{[\goalCmd{\prog}{\callCmd{p}{i}{o}}{\EmptyList}]}{\EmptyList}{\EmptySubst}{a}{\subst}~), ~$a$~ = ~\EmptyList~.
% \end{coqcode}

% The definition above explains what it means for a predicate to be deterministic. 
% The idea is that in a given program \prog and a predicate $p$,
% if for any call to $p$ with arbitrary input and output terms
% starting with the empty substitution and the empty list of alternatives,
% we have a solution, i.e. the couple $(a, \subst)$ then the list of
% alternatives $a$ is empty. This essentially means that any functional
% predicate produces no choice points.

% Following the literature, this claim is proven true:

% \begin{theorem}
%   Let \pred be a deterministic-annotated predicate, the following holds
%   \begin{coqcode}
%     Theorem ~\customlabel{is_detpred}{\texttt{det\_pred\_prop}}~(~\prog~: prog) (p: pn) :=
%       forall (HM : well_moded ~\prog\!\!~) (HD: det_check ~\prog\!\!~),
%           det_pred ~\prog~p
%   \end{coqcode}    
% \end{theorem}

% This to say that for any well-moded (hypothesis \coqIn{HM}) and
% determinacy-checked (hypothesis \coqIn{HD}) program and a predicate \pred such,
% then \pred is a deterministic predicate.

% \subsection{Contributions and paper structure}

% In our paper we will provide a description about a new dynamic mode and
% a new static determinacy
% checkers to verify that clauses are consistent wrt the signature the predicate has. We
% introduce these concepts with the \elpi programming language. We start by a
% light version of \elpi in the first-order setting, i.e. with no higher-order variables.
% In this part we explain our notion of modes, which have an inpact
% on the dynamic interpretation of the program. This will force us to slightly
% modify the interpreter in \cref{fig:basic-interp}. Moreover, thanks to these modes, we show that
% to statically guarantee the determinacy property of deterministic predicates
% we don't need any static mode analysis.

% In the second part of the paper we will extend the intepreter so that it can\todo{there are 3 parts}
% work with higher-order variables, hereditary-arrop clauses insertion and local
% $\forall$-quantified variable declaration. Here predicates will also take
% propositions as arguments. Thanks to this extention we will propose a new mode
% checking algorithm working with a new definition of groundness, called
% \textit{input-ground}. The signature of a predicate can be annotated so that
% output arguments are guaranteed to be deterministic. This will make the
% determinacy checker to analyse not only deterministic clauses but also relational
% one, since a check should be performed wrt the determinacy annotation of its
% outputs.