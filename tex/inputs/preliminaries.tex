\section{Preliminaries}

Before providing a formal definition of determinacy and mode analysis, we
first describe the language we are working with, namely a dialect of \lamprolog
called \elpi.

Since we have structured our paper into two main sections: 1) the first
discusses a basic version of \elpi with only Horn clauses and the cut operator,
and 2) the second extends this version by introducing hereditary-Harrop
formulas, we will keep the presentation of the types and functions we need
simple, expanding them further when needed.

Data are represented by terms. For now, terms live in the datatype, they are
variables, constants or compound terms. A compound term is term with a rigid
head followed by a list of other terms. 
Predicates are binary relations of type \\\elpiIn{tm -> tm -> prop}
where \elpiIn{tm} is a notation for term. The first argument of a predicate is
considered has its input and the second is its output. This choice aims to ease
the presentation of mode checking (see \cref{sec:modes}). By convention
variables are indicated with capital letters, whereas predicate names and
terms are indicated with lower case letters.

An atom is either a fully applied predicate or the cut operator, noted
\cut.

A variable is a term not yet instantiated. We can assign variables thanks to the
unification procedure. The notation \unifyCmd{t_1}{t_2}{\subst}{\subst[']} represents
the unification between the terms $t_1$ and $t_2$ from an intial substitution \subst
to a final substition \subst[']. A substitution is a mapping from a variable name to its
assignment $t$. Unification provides, when possible, a most general substitution
between the two terms. If this substitution, sometime called unifier, does not
exists, then the following property holds:

\begin{definition}[Unification negation]
  \vspace{-1em}
  $$(\forall \subst, \subst t_1 \neq \subst t_2) \to (\neg (\exists t_3~\subst_1~\subst_2,
  \subst_1 t_1 = \subst_1 t_3 \land \subst_2 t_2 = \subst_2 t_3))$$
\end{definition}

\begin{definition}[Substitution union]
  \vspace{-1em}
  $$\subst_1 \cap \subst_2  = \varnothing \to \subst_1\ t_1 = \subst_2\ t_2 \to (\subst_1 \cup \subst_2)\ t_1 = (\subst_1 \cup \subst_2)\ t_2$$
\end{definition}

The notation $\subst t$ is the application of a term to a substitution.
It returns a new term where all variables in $t$ have been recursively been
replaced by heir assignment in \subst.

A clause is made of a predicate name, its two arguments and a body made of a
list of atoms. The list of these atoms are called premises and should be
considered as a list of subgoals in conjunction. By convention a clause is noted
with ``\clauseCmd{p}{i\ o}{b}'' where p is the predicate name i and o are its
parameters and b is the body. It should be read as follows: if $b$ holds
then $p\ i\ o$ holds. 

A program is a mapping from predicate names to clauses. These clauses are in
disjunction and the order of their visit depend on the chronological order in
which clauses have been declared. We have no builtin \textit{or} operator but
it's behavior can be replicated by adding several implementation of the same
rule.

Unlike other prolog system, such as \mercury \cite{1996Somogy}, \elpi is not a
compiled language and we do not transform the list $\mathcal{L}$ of clauses of a
predicate $p$ in super-homogenous form, i.e. a sole clause containing the
disjunction of $\mathcal{L}$. This is mainly due to the fact that \elpi is an
homoiconic language and its program definition can change during the evaluation
of the code.

A program is a mapping from predicate names to clauses. By hypothesis, we assume
that every program we work with from now on has been type-checked (see
\cite{1992nadathur}). One of the role of type-checking is to ensure that
commands and expressions are not mixed: commands, also called propositions, are
pieces of executable code, whereas expressions are not. Instead, expressions
serve to carry pieces of information during the execution of commands.

A goal is a triple made of a program \prog, an atom
\g and the list of alternatives \alt existing at moment of the creation of 
the goal. We provide more details in some paragraph. 
% In particular,
% \g is evaluated by looking into the clauses inside \prog.
% \alt
% contains the choice-points used by the interpreter during the evaluation of a
% cut, the aim of this piece of data will be clarified further in the section
% dedicated to the interpreter implementation (see \cref{sec:basic-elpi}).

The interpreter takes a program a query and returns a substitution if the query
is a consequence of the program. Each time a predicate call has multiple clauses
implementing it, it commits the first choice and keep the other as global
alternatives. If that choice leads to a failure, the interpreter will try to
execute the first alternative. This non-deterministic behavior can be controlled
by the user thanks to the cut operator which allows to cut away unwanted choice
points.

TODO: dire cosa significa che una clausola can be applied successfully on a
goal.

To be more precise, we give below the type structure of each cunstruct we have
defined above:

\begin{coqcode}
  Definition pn := string. (*predicate names are strings*)
  Definition vn := string. (*variable  names are strings*)
  Inductive tm := 
    | Call (p:pn) (i:tm) (o:tm)  (*binary predicates taking integers*)
    | Cut                        (*the cut operator*)
    | Unify (t1:tm) (t2:tm)      (*unification between t1 and t2*)
    | Var (n:vname)              (*a variable*)
    | Lam (x: vn) (b:tm)         (*lam abstraction*)
    ...                          (*this is extended in section XX*)
  Inductive clause := Clause (p:pn) (i:tm) (i:tm) (A:list tm).
  Notation "P I O :- Bo" := (Clause P I O Bo).
  Notation "t1 = t2" := (Unify t1 t2).
  Definition sbst := T.
  Definition prog := pn -> list clause.
  Inductive goal := Goal (P:prog) (a:tm) (A:list alt) -> goal.
  with alt := sbst * list goal.
\end{coqcode}

The evaluation of a program is done through the \run\ predicate.
%
\begin{minted}[autogobble]{coq}
  Inductive run : goal -> list alt -> subst -> list alt -> subst := ...
\end{minted}

The inductive \coqIn{run} should be read as a relation between a goal \g, a list of
alternative \alt (which are in disjunction with the current goal) and an initial
substitution \subst. These three objects produce a new list of alternatives
\alt['] and a new substitution \subst[']. 
The notation \runCmd{\mathcal{G}}{\mathcal{A}}{\subst}{\mathcal{A}'}{\subst'}
stands for the a call to \run. Its system of rules is shown in \cref{fig:basic-interp}.

\begin{figure}
  
  \ruleStopM{.45}
  \ruleFailM{.45}
  \vspace{0.3em}%
  
  \ruleUnifM{.50}
  \ruleBangM{.40}
  \vspace{0.3em}%
  
  \ruleCallM{1}
  
  \caption{Dynamic semantics}
  \label{fig:basic-interp}
\end{figure}


% The idea is that the intepreter stops
% when it finds the first solution, which is a valid substitutions for the query
% wrt the program. In order to find all the solution of query from the current
% program, that is all the valid substutions for the query, it is sufficient to
% iterate over all the alternatives \alt['].

% In the following we use the following notation for call to the run predicate:
% %
% $$ \runCmd{\mathcal{G}}{\mathcal{A}}{\subst}{\mathcal{A}'}{\subst'} $$
% In this first section we start with a first-order version of a logic language.

It is an operational semantics similar to \cite{1990Vink}, where rules represent
the evolution from one configuration (below the line) to the next (above the
line). The choice to use operational semantics rather than denotational
semantics (as in \cite{2011king}) stems from our preference for maintaining a
concrete representation of the objects we manipulate. Instead of using
continuations to store the state of a choice point, we represent this
information as lists containing the alternatives, along with the substitution
that existed at the moment the choice point was created.


A query is a list of goals (noted with \g) put in cunjunction, whereas the
alternatives (noted \alt) represent a disjunction of goals. In the derivation
system, we use the two colon symbol ($::$) has separator between the head of a
list and its tail; $@$ stands for list concatenation; $\EmptyList$ is the empty list.
``$\prog\ \pred$'' is the application of \prog to the predicate $p$; it returns a list of
clauses. The function $\mathcal{F}$ is defined as follows:
%
$$
\mathcal{F}(\prog, \pred, i, o, \subst, \alt) := 
  [(\subst, (
      \Cons{(\prog, i = i', \alt)}
        \Cons{(\prog, o = o', \alt)}
          {[(\prog, g, \alt) \mid g \in bs]})) \mid \clauseCmd{\pred}{i'\ o'}{bs} \in \prog\ \pred]
$$

It takes a list of clauses, two terms $i$ and $o$,
a substitution $\subst$ and a list of alternatives \alt. For each clause
\clauseCmd{p}{i'\ o'}{bs}, it builds a new list of pairs where the first argument
is the substitution $\subst$ and the second are goals made by 1) the unification of
the first argument $i'$ with the first argument $i$ of the predicate call 2) the
unification between the second arguments $o'$ and $o$ 3) the map of each premise
$g$ in the body $bs$ which return a new list of goals having the program $p$,
the atom $g$ and the list of alternatives \alt.

The behaviour of the program depends on the shape of the list of goal and its
alternatives. A query succeed if exists a sequence of reductions allowing to reach the
\textit{stop rule}, symbolyzed with \ref{rule:stop}.

More precisely, the \textit{stop rule} captures configurations with an empty
list of goals. By convention, this configuration is final: there are no more
goals to process, so we stop and return the same alternatives and substitution
received as input.

The \textit{fail rule} (\ref{rule:fail}) consumes the list of alternatives if the
first goal fails. A failure occurs if the goal at the head of the list is a call
to a predicate with no clauses in the associated program or if it is a
failing unification under the given substitution.
% In fact, this
% rule allows to break loop since it can non-determinalistically applied on any
% configuration, provided that the list of alternatives is not empty. It is
% possible to make the algorithm deterministic by chainging \ruleFail so that it
% is applied if the current goal is a call to a predicate with no alternatives,
% but we prefer to simplify our rule system.

The \textit{unify rule} (\ref{rule:unif}) is applied when a unification $t_1 = t_2$
appears at the head of the current goal list. It invokes the \unify algorithm on
the two terms $t_1$ and $t_2$ using the substitution \subst and returns the
updated substitution \subst[']. Finally, if the unification succeeds, the \run\
procedure is called with the list of remaining goals \g and the new substitution
\subst['].

The \textit{cut rule} (\ref{rule:cut}) refers to goals where the first goal has the
\cut as atom. Since in our implementation we use the \textit{hard-cut} operator,
we proceed in solving the list of remaining goals but the alternatives we keep
are the one stored in the goal. This alternatives are called cut-alternatives.
As said in \cite{2003Andrews}, (hard-)cut is a non-logical operator ``cutting
away not only the later clauses of the same predicate, but also the alternative
clauses for subgoals that appear earlier in the clause''.

The \textit{call rule} (\ref{rule:call}) deals with goals starting with a predicate
call. In this case the function $\mathcal{F}$ is called with the parameters as
explained above and if the result of this operation is the list
\ConsHd{b}\ConsTl{bs}, then a recursive call to \run\ is done by prepending $b$ to
the list of remaining goals \g and $bs$ is prepended to the list of
alternatives \alt.

Note that we have intentionally kept out form \cref{fig:basic-interp}
the rule for variables appearing as goals. Variables will play an important role
in \cref{sec:vars}. 

The combination of the \ref{rule:call} and \ref{rule:cut} rules is crucial for replicating
the behavior of the cut. When a call to a predicate generates multiple rules as
new choice points, the function $\mathcal{F}$ creates future disjunctive goals
where the cut alternatives are set to the current list of alternatives \alt. In
other words, if the alternatives before reaching a call to a predicate \pred are
\alt and \prog is the current program, then if ``\prog \pred'' results in
clauses $c_0, \dots, c_n$, any clause $c_j$ with $i < j \leq n$ will be
discarded if clause $c_i$ contains a cut. Furthermore, if the body of $c_i$
consists of the atoms $a_1, \dots, a_k, !, a_{k+2}, \dots, a_m$, then all choice
points created during the evaluation of $a_1, \dots, a_k$ will also be pruned.
This pruning consist simply in setting the cut alternatives to \alt.

TODO: aggiungere nota: l'interprete lavora su termini che sono in canonical
form. La sostizione fa la beta reduction, nell'interprete di base questo succede
solo nel momento di chiamata a \unify. Nell'interpreter in \cref{sec:vars} si va
più lontano perchè il deref è fatto anche nelle call

As an example, let's consider the following program called \prog:

\begin{elpicode}
p1 X Y :- p2 X Y.           % r1
p1 3 3.                     % r2
p2 X Y :- p3 X Y, !, Y = 1. % r3
p2 1 1.                     % r4
p3 1 2.                     % r5
\end{elpicode}

{
\def\goalG{\goalCmd{\prog}{\callCmd{p1}{3}{Z}}{\EmptyList}}

Let $\mathcal{G} :=\ \goalG$ be a goal, the execution of
``\runCmd{\mathcal{G}}{\EmptyList}{\EmptySubst}{?A}{?\subst}'' will apply \ref{rule:call}
producing a new goal for the rule $r1$ and an alternative list containing $r2$,
we leave out details concerning unifications of head terms. The execution of
$r1$ will try to solve $r3$. This will add three goals \elpiIn{r 1 Y, !, Y = 1}
with cut-alternatives equal to $r2$ whereas the new alternatives will be $r4 @
r2$. The execution of $r3$ will solve \elpiIn{p3 1 Y} with substitution $s :=
\{X \gets 1; Y \gets 2\}$. The \elpiIn{!} will cut away the alternative $r4 @
r2$ and will keep the cut-alternative $r2$. The failing premise \elpiIn{Y = 1}
will cause a backtracking thanks to \ref{rule:fail} and try to apply $r2$ from the
empty substitution. This last unification succeed with final substution $?\subst :=
\{X \gets 3; Y \gets 3\}$ and final list of alternatives $?A := \EmptyList$.

% \begin{myRule}{1}
%   \AxiomC{}
%   \RightLabelM{\ruleCall}
%   \UnaryInfC{\runCmd{\mathcal{G}}{\EmptyList}{\EmptySubst}{?A}{?S}}
% \end{myRule}

}

% \subsection{The cut operator}
% \label{sec:cut}

% Logic programs are known for their non-deterministic behavior: there can be
% multiple distinct ways to derive a query from a knowledge base, and logic
% programs aim to find all of these solutions. While non-determinism is a key
% feature, it is sometimes important to allow the user to control if and when
% alternatives should be rejected. The cut operator is designed to address this
% problem.

% Since we use the elpi dialect of \lamprolog, it is important to clarify how
% the cut behaves in our development. It is that case that each prolog-ish language
% has its own cut implementation, for example in the official page of
% swi-prolog (\href{www.swi-prolog.org}{www.swi-prolog.org}) we see that
% there are two different cut implementations: the \textit{soft cut} noted with
% ``\texttt{C *-> T ; E}'' runs E if C has no solution otherwise the result is the
% same as running the conjunction of C and T. The \textit{hard cut} noted with the
% ``\texttt{!}'', "discards all choice points created since entering the predicate
% in which the cut appears".

% The \mercury system \cite{1996Somogy} is meant to be a pure programming language
% extended with types, modes, determinism and module systems. In order to satisfy
% its purity, \Mercury only accepts a version of the soft cut.

% It is also interesting to see that further representations of cut may exists,
% such as the firm cut explained in \cite{2003Andrews} where they provide a
% restricted version of the hard cut which has some concistency properties.

% \Elpi implementation uses the hard cut definition. Even though the hard cut have
% no equivalent representation from pure logic, we are convinced that, from a
% programming perspective, it is quite practical. It allows us to eliminate not
% only alternative implementations of a predicate but also to prevent backtracking
% of all choice points born from the begin of the clause-body to the current cut
% position.

% For example, in \elpi, the \textit{if-then-else} construct, which is not a\todo{wrong if pred are bin + no prop as arg}
% primitive of the language, can be impelented as follows:
% \begin{elpicode}
%   if C T E :- C, !, T. % if1
%   if _ _ E :- E.       % if2
% \end{elpicode}
% Due to the hard cut, the query ``\elpiIn{if C T E}'' executes the \texttt{if1} rule.
% If \elpiIn{C} has $n > 0$ solutions then only the first is kept, the other being
% cut away as the rule \texttt{if2}. The call then succeeds only if \elpiIn{T} has
% a solution. The rule \texttt{if2} will be run only if \elpiIn{C} has no
% solution.

% For example, in the following database:

% \begin{elpicode}
%   p 1.
%   p 2.
%   q 2.
% \end{elpicode}
% The query ``\elpiIn{if (p X) (q X) (0 = 1)}'' fails. Note that the usage of the
% soft-cut would make the same query to have a solution, since the backtracking in
% the condition would be authorized.
% \todo{cut di teyjus}

\subsection{Concerning modes}
\label{sec:modes}

Before talking about determinacy and the impact that hard-cut has on it. We
prefer to spend some few words about the definition of modes, because as
explained in \cite{1989Warren,1996Somogy} modes are the basis for determinim.

The general idea is that a logic program allows to express relations, but,
sometimes it is also needed to express \textit{directed} relations, where arguments are
differenciated between inputs and output. Said in an other way, output arguments
can be derived from input arguments. It is often the case that the user of a
logic programming langauge tend, in most of cases, to express directed
predicates. The typical example of this need is the \texttt{append} predicate
aiming to concatate two lists.

In a prolog-ish program without modes, the following program:

\begin{elpicode}
append [X|Xs] L [X|L'] :- append Xs L L'. % app1
append [] L L.                            % app2
\end{elpicode}

\noindent
makes the query ``\elpiIn{append Y [] L, 0 = 1}'' to diverge. 
Here the variable \elpiIn{Y} is unified with a list of infinite
length, the rule \texttt{app1} being continously applied.

Modes are there to avoid this situation. The most widespread mode definition
in the literature are two: the input
mode and the output mode. The idea is that each predicate is annotated with a
mode signature, and a static mode checker verifies that the clauses of the
program are consistent with the mode declrations of the predicates. Essentially,
in the head of a clause, 1) terms appearing in input position are supposed to be
ground whereas 2) terms in output position must become ground in the body of the
clause. Within each premise of the body, 3) terms appering in output positions become
ground while 4) terms appearing in input positions are checked to be ground. If
condition 2) or 4) are not satisfied a mode compilation error is raised.

In \twelf \cite{1996pfenning}, which is an implementation of \lamprolog, mode
checking is extended to work with local nominal variables and higher-order
variable unification within the pattern fragment.

\begin{definition}[Well-moded program (\wellModed)]
  \begin{coqcode}
    Definition ~\customlabel{wellmoded}{\texttt{well\_moded}}~ ~\prog\!\!~:
      forall p i o (HG: ground i) ~\subst \subst[']~, 
        (H: ~\runCmd{[\goalCmd{\prog}{\callCmd{\texttt{p}}{\texttt{i}}{\texttt{o}}}{\EmptyList}]}{\EmptyList}{\subst}{a}{\subst[']}~),
          ground (~\subst' ~o).
  \end{coqcode}
  \label{def:well-moded}
\end{definition}

The definition above can be rephrased as follows: a program \prog is well moded
if for any (binary in our setup) predicate \pred called with a ground input
\texttt{i} and any output term \texttt{o}, if the call succeeds producing a
substitution \subst['] then the application of that substitution to \texttt{o}
is a ground term.

It is interesting to note that mode checking under the groundness condition is
sometime too restrictive. In some situation it is in fact sufficient to work
with term that are "enough" ground to guarantee the wanted properties. As an
example, both \cite{1994apt-oc} and \cite{2002overton}, even though they
researches concern different areas, present a version of this mode checking with
"enough" instantiated terms together with some condition of variable linearty.

In our paper, we will combine these ideas. In particular,
since \elpi is used as a
meta-language for proof verification
\cite{tassi2018,tassi2019,tassi2023,fissore2023,fissore2024}, we
need to work with a higher-order setup where inputs (and outputs) may not be
fully instantiated: the role of the search engine is to potentially assign
unification variables. In the first part of the paper, we will introduce the
seamantics of the input mode which is used in \elpi. 
In the second part, we extend it so that it works with predicates taking
predicate calls as arguments.

\subsection{Concerning determinacy}
\label{sec:det}


Determinacy, as previously mentioned, is the property of a predicate that
returns at most one solution per call. Such a predicate behaves like a function,
which is why we refer to it as a deterministic predicate or simply a function.
Determinism checking statically ensures that the clauses implementing a
deterministic predicate adhere to this condition. The literature contains
numerous discussions on this topic, offering various descriptions and
applications of determinism.

In \cite{1989Warren}, the authors describe a property subsuming
determinism: they describe functionality. A predicate (clause or query) is
functional if it produces at most one \textit{distinct} solution per predicate
call. The key word here is \textit{distinct}, since, in the determinacy setting,
a predicate call producing the same solution twice is not considered as
deterministic, while, it is functional. %In the paper they explain that mutual
% exclusivness of clauses can be improved not only by looking at the head and at
% the presence of the cut but also by instructing the checker that premises can
% put clauses in mutual exclusivness.

In \cite{1991Sahlin}, and more formally in \cite{1996mogensen}, determinacy is
used to work with \mixtus, a partial evaluator of \prolog. In that case,
determinacy is inferred so that it is possible to derive a new specialiezed,
and therefore more efficient, version of the original program under the
guarantee that the two program share the same semantics.

Finally, in \cite{1996henderson}, a determinacy checker for \mercury
captures different behaviours of a predicate. A predicate can return
exactly zero and/or one solution, zero and/or multiple solution. In \mercury the
user is allowed to annotate predicates with determinacy information. A
non-annotated predicate will be inferred with the lowest derived tag.
Determinacy, in \mercury, besides giving a guarantee on the program, allows to
specialized it so that a faster routine can be used in the compiled program.

TODO: place the following definition somewhere
\begin{definition}[Deterministacy (\isdet)]
  Given a program \prog, a predicate \pred, an input $i$ and an output $o$ terms,
  \isdet is defined as follows:
  $\runCmd{[\goalCmd{\prog}{\callCmd{p}{i}{o}}{\EmptyList}]}{\EmptyList}{\EmptySubst}{a}{\subst} \to a = \EmptyList$
\end{definition}


We resume below the definitions and the properties
that are needed for determinacy checking.
%
% Under the hypothesis to work
% with program statically mode-checked, a necessary condition for a
% predicate to be deterministic is that no two clauses can be applied successfully
% on the same predicate call. Two clauses respecting this property are called
% mutually-exclusive.
%
To define this property, we first need to introduce some auxiliary definitions:
\cref{def:mut-excl,def:det-prem}.


\begin{definition}[Mutually-exclusive heads (\mutExclHeads)]
  % \begin{coqcode}
  %   Definition ~\customlabel{mutexcl}{\texttt{mutual\_exclusive}}\prog \pred\!\!~:
  %     ~$\forall\ i1\ o1\ bo1\ i2\ o2\ bo2$~ (H1: ~\clauseCmd{p}{i1\ o1}{bo1}~ \in ~$\prog\ p$~) (H2: ~\clauseCmd{p}{i2\ o2}{bo2}~ \in ~$\prog\ p$~),
  %         not (exists ~\subst\!\!~, ~\unifyCmd{i1}{i2}{\EmptySubst}{\subst}~)
  % \end{coqcode}
  Given two clauses
  $c_1 = \clauseCmd{\pred}{i_1\ o_1}{bo_1}$ and
  $c_2 = \clauseCmd{\pred}{i_2\ o_2}{bo_2}$ we have
  \begin{align*}
    \forall \subst, \lnot (\exists \subst['], \unifyCmd{i_1}{i_2}{\EmptySubst}{\subst[']})
  \end{align*}
  \vspace{-2em}
  \label{def:mut-excl-head} 
\end{definition}

That is, two clauses have mutually-exclusive heads if it does not exists a
substitution allowing to unify their inputs. Note that our clauses are
implementations of binary predicates whose areguments represent respectively
an input and output.

\begin{lemma}[Mutually-exclusive heads property]
  Given two clauses $c_1$ and $c_2$ with head respectively $h_1$ and $h_2$ then
  $$\mutExclHeads\ c_1\ c_2 \to \forall \subst_1\ \subst_2, \lnot (\exists t,
  \ground{t} \to \unifyCmd{t}{h_1}{\EmptySubst}{\subst_1} \land
  \unifyCmd{t}{h_2}{\EmptySubst}{\subst_2})$$
  \vspace{-2em}
  \label{th:mut-excl-head}
\end{lemma}

\begin{proof}
  By contradiction, let $t$ be a term unifying with both $h_1$ and $h_2$. This
  means that there exists two substitutions such that $\subst_1\ t = \subst_1\
  h_1$ and $\subst_2\ t = \subst_2\ h_2$. Since t is ground the equations can be
  simplified into: $t = \subst_1\ h_1$ and $t = \subst_2\ h_2$, implying that
  $\subst_1\ h_1 = \subst_2\ h_2$. Hoever, due to $\mutExclHeads\ c_1\ c_2$,
  $h_1$ and $h_2$ cannot be unified, therefore for any substituions
  $\subst[']_1$ and $\subst[']_2$, we have $\subst[']_1\ h_1 \neq \subst[']_2\
  h_2$, a contradiction.
\end{proof}

% \begin{coqcode}
%   Definition mutual_exclusive_head '(p i _ :- _) '(p i' _ :- _) :=
%     not (exists ~\subst\!\!~, ~\unifyCmd{i1}{i2}{\EmptySubst}{\subst}~)

%   Definition mutual_exclusive_cut c1 c2 :=
%     before c1 c2 -> with_cut c1
    
%   Definition mutual_exclusive prog p :=
%     forall c1 c2, c1 <> c2 -> c1 \in prog p -> c2 \in prog p ->
%       mutual_exclusive_clause c1 c2 \/ mutual_exclusive_cut c1 c2

% \end{coqcode}


\begin{definition}[Mutual-exclusion with \cut\ (\mutExclCut)]
  Given two clauses
  $c_1$ and $c_2$ such that $c_1$ is defined before $c_2$,
  the body of $c_1$ contains a \cut.
  \label{def:mut-excl+cut}
\end{definition}

\begin{lemma}[Mutually-exclusive \cut\ property]
  Given two clauses $c_1$ and $c_2$, if $\mutExclCut\ c_1\ c_2$, then
  $c_1$ and $c_2$ cannot be both applied simultaneously on the same goal.
  \label{th:mut-excl+cut}
\end{lemma}

\begin{proof}
  By induction on the derivation rules (\cref{fig:basic-interp}). The interesting case is the rule
  \ref{rule:call} when the heads $c_1$ and $c_2$ unify both with the current goal. If
  this is the case, then two cases should be taken into account: 1) the \cut\
  inside the body of $c_1$ is reached while running the program. In this case
  the \cut, will cut away the clause $c_2$ since, by contruction, it cannot
  appear in the cut-alternatives. 2) The \cut\ is not reached, that is, a failure
  occurs before reaching it. This means that the clause $c_1$ is not applied on
  the goal. In both cases both clauses cannot be applied simultaneously on the
  same goal.
\end{proof}

\begin{definition}[Mutual-exclusion (\mutExcl)]
  Given a program \prog and a predicate \pred. The clauses of \pred inside \pred
  are mutually exclusive if for any two pair of clauses, 
  $$\mutExclHeads\ c_1\ c_2 \lor \mutExclCut\ c_1\ c_2$$
  \vspace{-2em}
  \label{def:mut-excl}
\end{definition}

\begin{lemma}[Mutually-exclusion property]
  Forall program \prog and predicate \pred, such that $\mutExcl\ \prog\ \pred$,
  at most one clause can be run fron any call to \pred with ground input.
  \label{th:mut-excl}
\end{lemma}

\begin{proof}
  By \cref{th:mut-excl-head,th:mut-excl+cut}
\end{proof}

The second important condition
for determinacy is the following: 

\newcommand{\detAtom}{\texttt{det\_atom}}

\begin{definition}[Deterministic atom (\detAtom)]
  A atom is deterministic if it is a call deterministic-annotated predicate.
\end{definition}

\begin{definition}[Deterministic premises (\detPrem)]
  Let \prog be a program and \pred a deterministic-annotated predicate, then let
  $\prog\ \pred = c_1, \dots\ c_n$. For any body $b_i = a_1,\dots,a_m$ of any
  clause $c_i$,
  $$(\exists j, a_j = \cut \land \forall k, k > j \to \detAtom\ a_k) \lor (\forall j, \detAtom\ a_j)$$
  \vspace{-2em}
  \label{def:det-prem}
\end{definition}

This amout to say that in program \prog, a predicate \pred has deterministic
premises if the bodies of all its clauses either 1) have a \cut\ followed by
calls to deterministic predicates or 2) have only calls call to deterministic
predicates.

% \begin{lemma}[Deterministic premises property]
%   Let \prog and \pred be a program
%   $$\forall c, \prog\ \pred = [c] \to \wellModed\ \prog \to \runCmd{[\goalCmd{\prog}{\callCmd{p}{i}{o}}{\EmptyList}]}{\EmptyList}{\EmptySubst}{a}{\subst}, a = \EmptyList$$
%   \label{th:det-prem}
% \end{lemma}
% \begin{proof}
%   By induction on the derivation in \cref{fig:basic-interp}. The interesting
%   case is the \ruleCall. Since, by hypothesis, it exists only one clause $c$
%   implementing \pred in \prog, the recursive call has a new fresh list of goals
%   \g to treat (the premises $c$) and no choice points. Note that, by the
%   definition of the $\mathcal{F}$ function, all goal in \g has the empty list as
%   cut-alternatives. Two cases should be taken into account. 1) \g has a \cut.
%   Reaching the \cut\ will cut away all choice points which are set again to the
%   \empty list. After the \cut, all premises are call to deterministic
%   predicates. By induction hypothesis, this premises generates no choice points,
%   therefore the returned list of alternatives is the empty list, as expected. 2)
%   there is not \cut in \g, similarly to the previous case, all premises are call
%   to deterministic predicate, therefore we can conclude the proof using the
%   induction hypothesis.
% \end{proof}

\begin{definition}[Determinacy checking (\detCheck)]
  For any program \prog and any deterministic-annotated predicate \pred,
  $$\mutExcl\ \prog\ \pred \land \detPrem\ \prog\ \pred$$
\end{definition}

\begin{theorem}[Determinacy checking property]
  Given a program \prog and a predicate \pred\todo{la det\_check è su tutto il programma, non solo sulle regole per p}
  $$\wellModed\ \prog \to \detCheck\ \prog\ \pred \to \forall i\ o, \ground i\ \to \isdet\ \prog\ \pred\ i\ o$$
  \vspace{-20pt}
  \label{th:det}
\end{theorem}

\begin{proof}
  We can reason by induction on the derivations in \cref{fig:basic-interp}. The
  interesting case is the \ref{rule:call}. Due to \detCheck\ \prog \pred, we know, by
  \cref{th:mut-excl} that at most one clause $c$ successfully applies on the
  call to \pred. By definition of $\mathcal{F}$\todo{there are also unif}, the new goals \g are made from
  the atoms in $c$ and all of this goals have the empty list as
  cut-alternatives. We need to treat two cases. 1) \g has a cut. If all the
  goals before the \cut\ succeeds, then all the choice points generated are cut
  away. Moreover, since, by hypothesis, all the goals after the \cut\ are calls
  to deterministic predicates, and since, \wellModed\ \prog,
  we know that all of these call have at most one applying clause.
  We can now use the induction hypothesis on the remaining goals
  claiming that in the end the empty list of alternatives is produced,
  completing the proof for this case. 2) \g has not cut. The proof is similar
  to the previous one after haveing reached the cut.
\end{proof}

Several work of King et al \cite{king2005, king2006, 2011king} has been pursued
in order to build an inference model for determinacy in \prolog system with \cut.
Moreover, they explain that determinacy inference subsume determinacy checking.
Even though this last claim, we think that an inference model does not fit
well with our language.

The first motivation is that since \elpi is an interpreted dialect of \lamprolog,
program can change dynamically on the run of a program. This means that
rules can be added \textit{à la volée} making impossible to infer
determinacy as the user expects. 
It's 
up to the user to choose what should be the behavior of a predicate wrt
determinacy. The checker is meant to assist the user by rejecting, a predicate,
that does not respect the declared determinacy. 

As explained in some of the previously cited papers, determinacy (and so
functionality) checking is an undecidable problem. The checking property is
sound: if a predicate passes the analysis then it is for sure deterministic.
However, it is not complete: there could exists false negatives. We are
convinced, that completeness, is not a big deal, since, as also claimed in ...
every deterministic predicate not passing the determinacy check,
can be rewritten in a equivalent way
so that it is no more classified as non-deterministic.

% \begin{coqcode}
% Definition ~\customlabel{detpred}{\texttt{det\_pred}}~(~\prog~: prog) (p: pn) :=
%   forall ~$i$~ ~$o$~ ~$a$~ ~\subst~(HG: ground i) 
%     (H : ~\runCmd{[\goalCmd{\prog}{\callCmd{p}{i}{o}}{\EmptyList}]}{\EmptyList}{\EmptySubst}{a}{\subst}~), ~$a$~ = ~\EmptyList~.
% \end{coqcode}

% The definition above explains what it means for a predicate to be deterministic. 
% The idea is that in a given program \prog and a predicate $p$,
% if for any call to $p$ with arbitrary input and output terms
% starting with the empty substitution and the empty list of alternatives,
% we have a solution, i.e. the couple $(a, \subst)$ then the list of
% alternatives $a$ is empty. This essentially means that any functional
% predicate produces no choice points.

% Following the literature, this claim is proven true:

% \begin{theorem}
%   Let \pred be a deterministic-annotated predicate, the following holds
%   \begin{coqcode}
%     Theorem ~\customlabel{is_detpred}{\texttt{det\_pred\_prop}}~(~\prog~: prog) (p: pn) :=
%       forall (HM : well_moded ~\prog\!\!~) (HD: det_check ~\prog\!\!~),
%           det_pred ~\prog~p
%   \end{coqcode}    
% \end{theorem}

% This to say that for any well-moded (hypothesis \coqIn{HM}) and
% determinacy-checked (hypothesis \coqIn{HD}) program and a predicate \pred such,
% then \pred is a deterministic predicate.

\subsection{Contributions and paper structure}

In our paper we will provide a description about a new mode and functionality
checkers to verify that clauses are consistent wrt the user annotation. We
introduce these concepts with the \elpi programming language. We start by a
light version of \elpi in the first-order setting, i.e. with no $\lambda$-terms.
In this part we explain our notion of modes, which have an inpact
on the dynamic evaluation of the program. This will force us to slightly
modify our interpreter. Moreover, thanks to these modes, we show that
to statically guarantee the determinacy property of deterministic predicates
we don't need any static mode analysis.

In the second part of the paper we will extend the intepreter so that it can
work with higher-order variables, hereditary-arrop clauses insertion and local
$\forall$-quantified variable declaration. Here predicates will also take
propositions as arguments. Thanks to this extention we will propose a new mode
checking algorithm working with a new definition of groundness, called
\textit{input-ground}. The signature of a predicate can be annotated so that
output arguments are guaranteed to be deterministic. This will make the
determinacy checker to analyse not only deterministic clauses but also relational
one, since a check should be performed wrt the determinacy annotation of its
outputs.