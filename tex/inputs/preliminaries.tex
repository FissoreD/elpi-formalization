\section{Determinacy analysis for Horn Clauses with modes and cut}
\label{sec:basic}

% Before providing a formal definition of determinacy and mode analysis, we
% first describe the language we are working with, namely a dialect of \lamprolog
% called \elpi.

% Since we have structured our paper into two main sections: 1) the first
% discusses a basic version of \elpi with only Horn clauses and the cut operator,
% and 2) the second extends this version by introducing hereditary-Harrop
% formulas. Below we give a simple presentation of some basic 
% objects of our language, they will be expanded in next section when needed.
% \\

This section lays the foundation for our static analysis of Elpi by
focusing the fragment of Horn clauses with cut.

\subsection{Syntax}

By convention we say that predicates take first all input arguments and
then output arguments and we separather those with $\funsep$, omitting
the symbols when both are absent.
We use \pred{} for redicate names, \predVar{} for functor names
and $X$ for unification variable names. We write $\vecL{t}$ 
for $t_1 \ldots t_n$ (a possibly empty list of $t$s).
%and \texttt{c} for data types names.
In the syntax we single out the cut and equality predicates since they
have dedicated treatment in the operational semantics.

$$
  \begin{array}{c|c}
    syntax & types \\\hline
      \begin{array}{rl}
        atom   & ::= \cut \mid \pred\ \vecL{tm} \mid tm = tm \label{eq:atom} \\
        tm     & ::= \predVar\ \vecL{tm} \mid \X \label{eq:tm} \\
        clause & ::= \clauseCmd{\pred}{\vecL{tm}}{\vecL{atom}} \nonumber %\label{eq:cl} 
      \end{array} 
      \quad
      &
      \quad
      \begin{array}{rl}
        psign   & ::= \dtype{\relI}{\vecL{ty}}{\vecL{ty}} \ \label{eq:ty} \\
        ty   & ::= \texttt{exp} %\texttt{c}\ data^\ast \label{eq:data} 
      \end{array}  
    \\
  \end{array}
$$  
~\\
In this simple setting
all atoms have type \relI{},
all terms $tm$ have type \texttt{exp},
and a context \ctx{} assigns to each predicate symbol \pred{} a predicate signature $psign$.
For example, looking back at section~\ref{sec:examples},
we have that $\ctx~\texttt{likes} = \dtype{\relI}{\texttt{exp}}{\texttt{exp}}$
and $\ctx\ \texttt{true} = \relI$.
By convention given a call $\pred\ \vecL{t}$ to a n-ary predicate where
$\ctx\ \pred = \dtype{\relI}{{ty}_1 \ldots {ty}_k~}{~{ty}_{k+1} \ldots {ty}_n}$ we
write $\vecL{t_i}$ for the input arguments ${t}_1 \ldots {t}_k$
and $\vecL{t_o}$ for the output arguments ${t}_{k+1} \ldots {t}_n$.

We use $::$ for list cons; $@$ for list concatenation; $\EmptyList$ is the empty list;
$[e|x \in \vec{x}]$ for list comprehension and $[e\ \mathbf{if}\ p|x \in \vec{x}]$ 
for list filtering.

% \begin{minipage}{0.48\textwidth}%
%   \vspace{-1em}
%   \begin{align}
%     tm     & ::= \cut \mid \predVar\ \vecL{tm} \mid tm = tm \label{eq:tm} \\
%     ty     & ::= data \mid \dtype{\relI}{data^\ast}{data^\ast} \ \label{eq:ty} \\
%     data   & ::= \texttt{c}\ data^\ast \mid \predVar \label{eq:data}
%   \end{align}  
% \end{minipage}
% \begin{minipage}{0.48\textwidth}
%   \vspace{-1em}
%   \begin{align}
%     clause & ::= \clauseCmd{\pred}{\vecL{tm}}{\vecL{tm}}                  \label{eq:cl}  \\
%     goal   & ::= \goalCmd{\prog}{tm}{\vecL{alt}} \label{eq:goal}                            \\
%     alt    & ::= \texttt{subst} * \vecL{goal} \label{eq:alt}
%   \end{align}  
% \end{minipage}

% In this simple

% Terms are shown in \cref{eq:tm}. They are made by the \cut\ operator
% (usually noted \elpiIn{!}); term application, we use the symbol \predVar\
% to indicate variable names, they can be either predicate names, i.e. constants
% of the program, or quantified variables. An application is followed by a
% vector of terms. Term unification is a special case of term application,
% we prefer to have a special case for it. 
% By convention we differentiate unification variables from constants
% by indicating the former with capital letters and the latters
% with lower case letters.



% Each term in the language has a type (\cref{eq:ty}). The type is either a
% $data$, that is the type of expressions or a $pred$ the type for predicates,
% that is the type of executable piece of code. Predicates are parametrized by
% arguments whose type are of type $data$. $data$ (\cref{eq:data}) are made by
% constants applied to list of data, we have for example the type \elpiIn{int} or
% \elpiIn{list}, and \predVar\ stands for variables, allowing therefore to have
% polymorphism.

% A clause (\cref{eq:cl}) is made of a variable name, its list of arguments and a body made of a
% list of terms. This list of terms are called \textit{premises} and should be
% considered as a list of subgoals in conjunction.

\subsection{Operational semantics}

A program \prog is a mapping from predicate names to an ordered
list of clauses; we write $\prog~\pred$ for the clauses for
predicate \pred.
We assume all predicates have at least one clause, in particular
$\prog\ \texttt{fail} = [\clauseCmd{\texttt{fail}}{\!\!}{0 = 1}]$.
% These clauses are
% disjunctive, and the order in which they are explored follows the chronological
% order of their declaration.
%
% In our approach, we do not include built-in operators, keeping the language as
% minimalist as possible. For instance, there is no built-in \textit{or} operator.
% However, its behavior can be replicated by defining a custom \textit{or}
% predicate with two arguments and providing two implementations: one invoking the
% first argument and the other invoking the second.
%
% A program is a mapping from predicate names to clauses. By hypothesis, we assume
% that every program we work with from now on has been type-checked (see
% \cite{1992nadathur}). One of the role of type-checking is to ensure that
% commands and expressions are not mixed: commands, also called propositions, are
% pieces of executable code, whereas expressions are not. Instead, expressions
% serve to carry pieces of information during the execution of commands.
%
%   \begin{align}
%     clause & ::= \clauseCmd{\pred}{\vecL{tm}}{\vecL{tm}}                  \label{eq:cl}  \\
%     goal   & ::= \goalCmd{\prog}{tm}{\vecL{alt}} \label{eq:goal}                            \\
%     alt    & ::= \texttt{subst} * \vecL{goal} \label{eq:alt}
%   \end{align}  
%
%
A goal $g \in \g \subseteq \prog \times atom \times \vecL{\alt}$
is a triple made of a program, an atom $g$ and a list of \emph{cut-to} alternatives.
An alternative $a \in \alt \subseteq \Sigma \times \vecL{\g}$ is a
pair made of a substitution and a list of goals.

We say that $\vars\ t \subset \X$ is the set
of variables occurring in $t$. When $\vars\ t = \emptyset$ we way that
$t$ is \ground.
A substitution $\subst : \X \to tm$ is a mapping from unification variables
to terms. 
We write $\subst t$ the application of a substitution \subst to a term $t$,
and we remark that $t$ is \ground{} iff $\forall \subst, \subst t = t$.
We write $\mathrm{dom}\ \subst$ for the set of variables occurring
in the domain or in the codomain of \subst, i.e.
$\dom \subst = \{ X\ |\ \subst X \mathrm{\ defined\ } \lor X \in \vars\ (\subst Y) \mathrm{\ for\ some\ Y} \}$.
We write $\EmptySubst$ for the only
substition s.t. $\dom\ \EmptySubst = \emptyset$.
When two substitutions have disjoint domains we write $\sigma_1 \cup \sigma_2$
as the (disjoint) union of two substitutions.

We assume a unifier $\unify : tm \times tm \times \Sigma \to \Sigma \uplus \bot$
such that if $\matchCmd{t_1}{_2}{\subst}{\subst[']} \not= \bot$ then $\subst['] t_1 = \subst['] t_2$
and $\subst[']$ is the most general extension (in the usual sense) of  $\subst$.
We assume a matcher $\match : tm \times tm \times \Sigma \to \Sigma \uplus \bot$
such that if $\matchCmd{t}{p}{\subst}{\subst[']} \not= \bot$ then $\subst t = \subst['] p$
and $\subst[']t = t$ and $\subst[']$ is the most general extension of  $\subst$,
i.e. \match{} does not assign variables in $t$ but only in the (pattern) $p$.
We shall fold \unify{} and \match{} over a list of pairs of terms
using the combinator defined by these equations:

$$
\texttt{fold}(\_,\ \_,\ \bot) = \bot
\quad
\texttt{fold}((t,u) :: l,\ f,\ x) = \texttt{fold}(l,\ f,\ f\ t\ u\ x)
\quad
\texttt{fold}(\EmptyList,\ \_,\ x) = x
$$

The operational semantics of our language is given by a relation
$\run{} \subseteq \alt \times \vecL{\alt} \times (\vecL{\alt} \times \Sigma ~\uplus~ \bot)$.
We write \runCmd{gl}{a}{\subst}{a'}{\subst'}
when a goal list $gl$ under a substitution \subst and alternatives $a$
terminates with a substitution $\subst'$ and a remaining list of
(still unexplored) alternatives $a'$. We write  \runCmdF{gl}{a}{\subst}
when the execution halts: fails to solve one of the given goals and runs out of
alternatives.

The rules for \run{} are given in~\cref{fig:basic-interp}\todo{rule per fail?}.
An initial query looks like \runQuery{[\goalCmd{\prog}{\pred\ \vecL{t}}{\EmptyList}]}{\EmptyList}
In this section the program never changes during execution hence storing it
in the goal seems useless, but the program will change dynamically
in section~\ref{sec:hoas} where the implication operator \elpiIn{=>} is
introduced.

\begin{figure}[!h]

  \ruleBangM{.50}
  \ruleStopM{.45}
  \vspace{0.3em}%

  \ruleCallM{1}
  $$
  \mathcal{F}(\prog, \pred\ \vec{t}, gl, \subst, a) :=
  \bigg[
    %\bigg(
    \subst['],
    %\Big(
    %\underbrace{
      \big[(\prog, g, a) \mid g \in \vecL{g}\big]
    %}_{\mathrm{premises}} @ ~ gl
    \ \mathbf{if}\ \mathcal{H}(\vecL{tu}, \subst) = \subst['] \not= \bot,
    %\Big)
    %\bigg)
    ~\bigg\rvert~
    (\clauseCmd{\pred}{\vec{u}}{\vecL{g}}) \in \prog\ \pred
    \bigg]
  $$

  $$
  \mathcal{H}(\vecL{tu},\ ol,\ \subst) = \texttt{fold}(\vecL{tu_o},\ \unify,\ \texttt{fold}(\vecL{tu_i},\ \match,\ \subst))
  $$

  \ruleCallMF{0.5}
  \ruleCallMFH{0.44}

  \rulePiImplM{.7}
  \ruleCallBeta{0.44}



  % $$
  % \mathcal{F}(\prog, \pred\ \vec{t}, gl, \subst, a) :=
  % \bigg[
  %   %\bigg(
  %   \subst,
  %   %\Big(
  %   \underbrace{\big[(\prog, t = u, ~a) \mid (t,u) \in \vecL{t,u}\big]}_{\mathrm{head\ unification}} @
  %   \underbrace{\big[(\prog, g, a) \mid g \in \vecL{g}\big]}_{\mathrm{premises}} @ ~ gl
  %   %\Big)
  %   %\bigg)
  %   ~\bigg\rvert~
  %   (\clauseCmd{\pred}{\vec{u}}{\vecL{g}}) \in \prog\ \pred
  %   \bigg]
  % $$


  % \ruleUnifM{.6}
  % \ruleFailM{.55}
  % \ruleAbortM{.4}
  \vspace{0.3em}%

  \caption{Operational natural semantics}
  \label{fig:basic-interp}
\end{figure}

The first rule to look at is the one for cut (\ref{rule:cut}).
Remark that the cut-to alternatives stored in each goal are a suffix
of the (global) alternatives to that goal: If the atom in the goal
is a cut, then the global alternatives are shortened to the cut-to ones.

This rule goes hand in hand with~\ref{rule:call} that stores
the current alternatives \alts in all the subgoals via
the function $\mathcal{F}$. This function is in charge of creating the
new alternatives $\alts['] :: al$;
the former is directly evaluated while
the rest prepended to the existing set of alternatives.
Each alternative is made of a prefix of unifications, one for each argument
of the predicate, followed by the premises of the clause and by the pre-existing
goals $gl$. 

The stop rule~\ref{rule:stop} terminates as there are no more goals to be
solved and produces the current susbtitution and the yet to be explored
alternatives.

Rules \ref{rule:unif}, \ref{rule:abort} and \ref{rule:backtrack} deal
with equational goals by calling \unify algorithm. If it succeeds
then we move to the next goal. If it fails we move to the next alternative.
If no alternative is available we halt.

This operational semantisc is essentially a big-step version of
the one given in~\cite{1990Vink}. The choice to use operational semantics
rather than denotational semantics (as in \cite{2011king}) stems from our
preference for maintaining a concrete representation of the current choice
points as well as the cut-to ones (the ones obtained when a cut is performed).
\todo{se is\_det usasse $\EmptyList$ sarebbe mglio...}
This semantics describes an SLD search strategy with a \textit{hard-cut} operator
in the sense of~\cite{2003Andrews}: it is cutting
away not only the later clauses of the same predicate, but also the alternative
clauses for subgoals that appear earlier in the clause premises.

% The \textit{call rule} (\ref{rule:call}) deals with goals starting with a predicate
% call, \pred\ is the notation to represent predicate name. In this case the function $\mathcal{F}$ is called with the parameters as
% explained above and if the result of this operation is the list
% \ConsHd{b}\ConsTl{bs}, then a recursive call to \run\ is done by prepending $b$ to
% the list of remaining goals \g and $bs$ is prepended to the list of
% alternatives \alt.

% The combination of the \ref{rule:call} and \ref{rule:cut} rules is crucial for replicating
% the behavior of the cut. When a call to a predicate generates multiple rules as
% new choice points, the function $\mathcal{F}$ creates future disjunctive goals
% where the cut alternatives are set to the current list of alternatives \alt. In
% other words, if the alternatives before reaching a call to a predicate \pred are
% \alt and \prog is the current program, then if ``\prog \pred'' results in
% clauses $c_0, \dots, c_n$, any clause $c_j$ with $i < j \leq n$ will be
% discarded if clause $c_i$ contains a cut. Furthermore, if the body of $c_i$
% consists of the atoms $a_1, \dots, a_k, !, a_{k+2}, \dots, a_m$, then all choice
% points created during the evaluation of $a_1, \dots, a_k$ will also be pruned.
% This pruning consist simply in setting the cut alternatives to \alt.

% It takes program \prog, a predicate name \pred, a list of terms,
% a substitution $\subst$ and a list of alternatives \alt. For each clause
% \clauseCmd{p}{\vec{t'}}{bs}, it builds a new list of pairs where the first argument
% is the substitution $\subst$ and the second is the list of new goals to treat.
% This list is made by all the unification between the terms received at call
% time and the argument of the clause and is followd by the premises
% of the clause that have been transformed in a goal.


% The \textit{fail rule} (\ref{rule:backtrack}) consumes the list of alternatives if the
% first goal fails. A failure occurs if the goal at the head of the list is a call
% to a predicate with no clauses in the associated program or if it is a
% failing unification under the given substitution.
% In fact, this
% rule allows to break loop since it can non-determinalistically applied on any
% configuration, provided that the list of alternatives is not empty. It is
% possible to make the algorithm deterministic by chainging \ruleFail so that it
% is applied if the current goal is a call to a predicate with no alternatives,
% but we prefer to simplify our rule system.


% A variable is a term not yet instantiated. We can assign variables thanks to the
% \unify\ procedure. It is used each time a term like $t_1 = t_2$ is encountered
% while solving a goal. The notation \unifyCmd{t_1}{t_2}{\subst}{\subst[']} is
% the unification and between the terms $t_1$ and $t_2$. It also takes an initial substitution \subst
% which is updated into the final substition \subst[']. A substitution is a mapping from variables name to their
% assignment. An assignment is a term. Unification provides, when possible, a most general unifier
% between the two terms. 


% existing at moment of the creation of
% the goal. A query is a list of goals (noted \g in the following) in conjunction, whereas alternatives
% (\cref{eq:alt}, noted \alt in the following) represent a disjunction of goals.
% In particular,
% \g is evaluated by looking into the clauses inside \prog.
% \alt
% contains the choice-points used by the interpreter during the evaluation of a
% cut, the aim of this piece of data will be clarified further in the section
% dedicated to the interpreter implementation (see \cref{sec:basic-elpi}).

% The interpreter takes a program a query and returns a substitution if the query
% is a consequence of the program. Each time a predicate call has multiple clauses
% implementing it, it commits the first choice and keep the other as global
% alternatives. If the committed choice leads to a failure, the interpreter will try to
% execute the first alternative. This non-deterministic behavior can be controlled
% by the user thanks to the cut operator which allows to cut away unwanted choice
% points.

% We say that a clause applies on the goal if its head unifies with a goal
% and we say that it \textit{successfully} unifies with a goal if the clause
% applies on the goal and all premises in its body succeed.

% \begin{coqcode}
%   Definition pn := string. (*predicate names are strings*)
%   Definition vn := string. (*variable  names are strings*)
%   Inductive tm := 
%     | Call (p:pn) (i:tm) (o:tm)  (*binary predicates taking integers*)
%     | Cut                        (*the cut operator*)
%     | Unify (t1:tm) (t2:tm)      (*unification between t1 and t2*)
%     | Var (n:vname)              (*a variable*)
%     | Lam (x: vn) (b:tm)         (*lam abstraction*)
%     ...                          (*this is extended in section XX*)
%   Inductive clause := Clause (p:pn) (i:tm) (i:tm) (A:list tm).
%   Notation "P I O :- Bo" := (Clause P I O Bo).
%   Notation "t1 = t2" := (Unify t1 t2).
%   Definition sbst := T.
%   Definition prog := pn -> list clause.
%   Inductive goal := Goal (P:prog) (a:tm) (A:list alt) -> goal.
%   with alt := sbst * list goal.
% \end{coqcode}

% The evaluation of a program is done through the \run\ predicate. It is a
% function with the following signature:
% %
% $$run : goal \to \vecL{alt} \to subst \to (\vecL{alt} * subst)$$
%
% \begin{minted}[autogobble]{coq}
%   Inductive run : goal -> list alt -> subst -> list alt -> subst := ...
% \end{minted}

% \coqIn{run} should be understood as a relation between a goal \g, a list of
% alternatives \alt (which are disjunctive with the current goal), and an initial
% substitution \subst. These three components produce a new list of alternatives
% \alt['] and an updated substitution \subst['].
% The notation \runCmd{\mathcal{G}}{\mathcal{A}}{\subst}{\mathcal{A}'}{\subst'}
% represents calls to \run. 



% The idea is that the intepreter stops
% when it finds the first solution, which is a valid substitutions for the query
% wrt the program. In order to find all the solution of query from the current
% program, that is all the valid substutions for the query, it is sufficient to
% iterate over all the alternatives \alt['].

% In the following we use the following notation for call to the run predicate:
% %
% $$ \runCmd{\mathcal{G}}{\mathcal{A}}{\subst}{\mathcal{A}'}{\subst'} $$
% In this first section we start with a first-order version of a logic language.


% of the objects we manipulate. Instead of using
% continuations to store the state of a choice point, we represent this
% information as lists containing the alternatives, along with the substitution
% that existed at the moment the choice point was created.

% As an example, let's consider the following program called \prog:

% \begin{elpicode}
%   p1 X Y :- p2 X Y.           % r1
%   p1 3 3.                     % r2
%   p2 X Y :- p3 X Y, !, Y = 1. % r3
%   p2 1 1.                     % r4
%   p3 1 2.                     % r5
% \end{elpicode}

% {
% \def\goalG{\goalCmd{\prog}{\callCmd{\texttt{p1}}{3\ Z}}{\EmptyList}}

% Let $\mathcal{G} :=\ \goalG$ be a goal, the execution of
% ``\runCmd{\mathcal{G}}{\EmptyList}{\EmptySubst}{?A}{?\subst}'' will apply \ref{rule:call}
% producing a new goal for the rule $r1$ and an alternative list containing $r2$,
% we leave out details concerning unifications of head terms. The execution of
% $r1$ will try to solve $r3$. This will add three goals \elpiIn{r 1 Y, !, Y = 1}
% with cut-alternatives equal to $r2$ whereas the new alternatives will be $r4 @
%   r2$. The execution of $r3$ will solve \elpiIn{p3 1 Y} with substitution $s :=
%   \{X \gets 1; Y \gets 2\}$. The \elpiIn{!} will cut away the alternative $r4 @
%   r2$ and will keep the cut-alternative $r2$. The failing premise \elpiIn{Y = 1}
% will cause a backtracking thanks to \ref{rule:backtrack} and try to apply $r2$ from the
% empty substitution. This last unification succeed with final substution $?\subst :=
%   \{X \gets 3; Y \gets 3\}$ and final list of alternatives $?A := \EmptyList$.

% % \begin{myRule}{1}
% %   \AxiomC{}
% %   \RightLabelM{\ruleCall}
% %   \UnaryInfC{\runCmd{\mathcal{G}}{\EmptyList}{\EmptySubst}{?A}{?S}}
% % \end{myRule}

% }

% \subsection{The cut operator}
% \label{sec:cut}

% Logic programs are known for their non-deterministic behavior: there can be
% multiple distinct ways to derive a query from a knowledge base, and logic
% programs aim to find all of these solutions. While non-determinism is a key
% feature, it is sometimes important to allow the user to control if and when
% alternatives should be rejected. The cut operator is designed to address this
% problem.

% Since we use the elpi dialect of \lamprolog, it is important to clarify how
% the cut behaves in our development. It is that case that each prolog-ish language
% has its own cut implementation, for example in the official page of
% swi-prolog (\href{www.swi-prolog.org}{www.swi-prolog.org}) we see that
% there are two different cut implementations: the \textit{soft cut} noted with
% ``\texttt{C *-> T ; E}'' runs E if C has no solution otherwise the result is the
% same as running the conjunction of C and T. The \textit{hard cut} noted with the
% ``\texttt{!}'', "discards all choice points created since entering the predicate
% in which the cut appears".

% The \mercury system \cite{1996Somogy} is meant to be a pure programming language
% extended with types, modes, determinism and module systems. In order to satisfy
% its purity, \Mercury only accepts a version of the soft cut.

% It is also interesting to see that further representations of cut may exists,
% such as the firm cut explained in \cite{2003Andrews} where they provide a
% restricted version of the hard cut which has some concistency properties.

% \Elpi implementation uses the hard cut definition. Even though the hard cut have
% no equivalent representation from pure logic, we are convinced that, from a
% programming perspective, it is quite practical. It allows us to eliminate not
% only alternative implementations of a predicate but also to prevent backtracking
% of all choice points born from the begin of the clause-body to the current cut
% position.

% For example, in \elpi, the \textit{if-then-else} construct, which is not a\todo{wrong if pred are bin + no prop as arg}
% primitive of the language, can be impelented as follows:
% \begin{elpicode}
%   if C T E :- C, !, T. % if1
%   if _ _ E :- E.       % if2
% \end{elpicode}
% Due to the hard cut, the query ``\elpiIn{if C T E}'' executes the \texttt{if1} rule.
% If \elpiIn{C} has $n > 0$ solutions then only the first is kept, the other being
% cut away as the rule \texttt{if2}. The call then succeeds only if \elpiIn{T} has
% a solution. The rule \texttt{if2} will be run only if \elpiIn{C} has no
% solution.

% For example, in the following database:

% \begin{elpicode}
%   p 1.
%   p 2.
%   q 2.
% \end{elpicode}
% The query ``\elpiIn{if (p X) (q X) (0 = 1)}'' fails. Note that the usage of the
% soft-cut would make the same query to have a solution, since the backtracking in
% the condition would be authorized.
% \todo{cut di teyjus}

\subsection{Static analysis: modes}
\label{sec:modes}

% Before talking about determinacy and the impact that hard-cut has on it. We
% prefer to spend some few words about the definition of modes, because
As explained in \cite{1989Warren,1996Somogy} modes are the basis for determinim.
Predicate arguments are classified as input or output and mode analysis
ensures that at call time inputs are ground and that the outputs are eventually
bound to ground terms. In turn a ground input is necessary
to justify the following check.

\begin{definition}[Unifiable (\unifiable) and not unifyable (\nUnify)]
We say that $\unifiable\ t_1\ t_2$ iff
  $\exists\ \subst\ s.t.\ \unifyCmd{t_1}{t_2}{\EmptySubst}{\subst}$.
We say that $\nUnify\ t_1\ t_2$ iff
  $\forall \subst \ \unifyCmd{t_1}{t_2}{\subst}{\bot}$ (equivalently, since
  \unify is complete, $\neg \exists \subst\ s.t. \subst t_1 = \subst t_2$).
\end{definition}

\begin{definition}[Mutually-exclusive heads (\mutExclHeads) at $d$]
  \label{def:mut-excl-head}
  % \begin{coqcode}
  %   Definition ~\customlabel{mutexcl}{\texttt{mutual\_exclusive}}\prog \pred\!\!~:
  %     ~$\forall\ i1\ o1\ bo1\ i2\ o2\ bo2$~ (H1: ~\clauseCmd{p}{i1\ o1}{bo1}~ \in ~$\prog\ p$~) (H2: ~\clauseCmd{p}{i2\ o2}{bo2}~ \in ~$\prog\ p$~),
  %         not (exists ~\subst\!\!~, ~\unifyCmd{i1}{i2}{\EmptySubst}{\subst}~)
  % \end{coqcode}
  Given a context \ctx\ and two clauses $c_1$ and $c_2$ with head,
  respectively, $\pred\ t_1 \ldots t_n$ and $\pred\ u_1 \ldots u_n$.
  Let $\ctx\ \pred = \dtype{\relI}{i_1 \ldots i_k}{\_}$, then we say that
  $\mutExclHeads\ c_1\ c_2\ d$ holds iff $d \leq k\ \land\ \nUnify\ t_d\ u_d$.
\end{definition}

This static check is used to justify the fact that, at run time, either
$c_1$ or $c_2$ is used for a given goal. For this to be true one needs
its discriminating argument at position $d$ to be ground in the call.
The reasoning goes as follows.

% \begin{lemma}[Split transitivity] Given
% two terms $t_1$ and $t_2$ such that $\nUnify~ t_1\ t_2$, there is no ground term
% $t_3$ such that $\unifiable\ t_1\ t_3$ and $\unifiable\ t_3\ t_2 $.
% \end{lemma}

\begin{lemma}[Mutually-exclusive heads property]
  \label{th:mut-excl-head}
  Given a context $\ctx\ $and two clauses $c_1$ and $c_2$
  with heads, respectively, $\pred\ t_1 \ldots t_n$ and $\pred\ u_1 \ldots u_n$.
  % let $\vec{t}_i$ and $\vec{u}_i$ be the inputs arguments of $\vec{t}$ and $\vec u$ respectively.
  % forall vector of \textit{ground} terms $\vec{v}$,
  $$\mutExclHeads\ \ctx\ c_1\ c_2\ d \to \lnot \exists v\ s.t.\ 
    \ground\ v\ \land\ \unifiable\ v\ t_d \land\ 
    \unifiable\ v\ u_d$$
  \vspace{-2em}
\end{lemma}
\begin{proof}
  By contradiction, let $v$ be a ground term $t_d$ and $u_d$. This
  means that there exists two substitutions $\subst_1$ and $\subst_2$ s.t.
  $\subst_1 v = \subst_1 t_d$
  and $\subst_2 v = \subst_2 u_d$. Since $v$ is ground the equations can be
  simplified to $v = \subst_1 t_d$ and $v = \subst_2 u_d$, hence by transitivity
  $\subst_1 t_d = \subst_2 u_d$. However, by definition of $\mutExclHeads\ \ctx\ c_1\ c_2\ d$
  we have that $\nUnify\ t_d\ u_d$: 
  % for any substituions
  % $\subst[']_1$ and $\subst[']_2$, we have $\subst[']_1\ t_d \neq \subst[']_2\ u_d$,
  a contradiction since $\subst_1 \cup \subst_2$ unifies $t_d$ with $u_d$ and
  we can form that substitution since
  $\dom\ \subst_1 \cap \dom\ \subst_2 = \emptyset$ because
  the domains 
  $\vars\ t_d$ and $\vars\ u_d$ are disjoint (the clause variables are fresh
  at each application) and since the there are no variabels in the codomain,
  since all terms are subterms of $v$ that is ground.
\end{proof}


% The general idea is that a logic program allows to express relations, but,
% sometimes it is also needed to express \textit{directed} relations, where arguments are
% differenciated between inputs and output. Said in an other way, output arguments
% can be derived from input arguments. It is often the case that the user of a
% logic programming langauge tend, in most of cases, to express directed
% predicates. The typical example of this need is the \texttt{append} predicate
% aiming to concatate two lists.

% In a prolog-ish program without modes, the following program:

% \begin{elpicode}
%   append [X|Xs] L [X|L'] :- append Xs L L'. % app1
%   append [] L L.                            % app2
% \end{elpicode}

% \noindent
% makes the query ``\elpiIn{append Y [] L, 0 = 1}'' to diverge.
% Here the variable \elpiIn{Y} is unified with a list of infinite
% length, the rule \texttt{app1} being continously applied.

% In \twelf \cite{1996pfenning}, which is an implementation of \lamprolog, mode
% checking is extended to work with local nominal variables and higher-order
% variable unification within the pattern fragment,

% Modes are there to avoid this situation. The most widespread mode definition
% in the literature are two: the input
% mode and the output mode. The idea is that each predicate is annotated with a
% mode signature, and a static mode checker verifies that the clauses of the
% program are consistent with the mode declrations of the predicates. Essentially,
% in the head of a clause, 1) terms appearing in input position are supposed to be
% ground whereas 2) terms in output position must become ground in the body of the
% clause. Within each premise of the body, 3) terms appering in output positions become
% ground while 4) terms appearing in input positions are checked to be ground. If
% condition 2) or 4) are not satisfied a mode compilation error is raised.

\begin{definition}[Well-moded program and well-moded call (\wellModed)]\label{def:well-moded}
We say $\wellModed\ \prog$ if the static analysis given in \cite{1996pfenning}\todo{cita anche altri}
succeeds. We say $\wellModed\ (\pred\ \vecL{t})$ if
$\ground\ t$ for all $t \in \vecL{t_i}$.
\end{definition}

% \begin{definition}[$\fail\ a\ al$]
% We say $\fail\ a\ al$ iff $\runCmdFQ{a}{al}$
% \end{definition}

\begin{theorem}[Mutually-exclusive clauses property]
  Given any $\ctx$ and any predicate $\prog$ that holds two clauses $c_1$ and
  $c_2$ for $\pred$ such that $\mutExclHeads\ \ctx\ c_1\ c_2\ d$,
  then any $\wellModed\ (\pred\ \vec{t})$ is such that
  $$
    \mathcal{F}(\prog, \pred\ \vec{t}, \subst, \alts) = [\alts[_1], a_2]
    \to
    \runCmdQ{a_1}{\EmptyList}{\subst}{a'} \to
    \runCmdFQ{a_2}{\EmptyList}
    % \lnot \exists \subst' a'', \runCmdQ{a_2}{\EmptyList}{\subst[']}{a''}
$$
    
  \label{th:mut-excl-head}
\end{theorem}
% \begin{proof}Follows from \ref{th:mut-excl-head}
% \end{proof}





% The definition above can be rephrased as follows: a program \prog is well moded
% if for any (binary in our setup) predicate \pred called with a ground input
% \texttt{i} and any output term \texttt{o}, if the call succeeds producing a
% substitution \subst['] then the application of that substitution to \texttt{o}
% is a ground term.

\subsection{Static analysis: Operational determinacy}
\label{sec:det}

Our objective is to indentify predicates that repsent mathamtical
functions rather than relations.
The literature on determinacy analysis goes beyond this coarse categorization,
for example by identifying functions with an empty or full
domain~\cite{1996henderson} or predicate that are observably functions in the sense that
that can return multiple times the same result, or diverge~\cite{1989Warren}.

We are interested in identifying predicates that leave no choice points~\ref{def:is-def}
called \emph{semidet} in \cite{1996henderson}, or in the wording of \cite{nakamura1986}
are \emph{operationally deterministic}.

\begin{definition}[Terminating functionality (\isfunc)]\label{def:is-func}
  Given a program \prog and an atom $g$ we say that
  $\isfunc\ \prog\ g$ iff $\isFuncCmd{t}$. It is stronger than
  functional in the sense of~\cite{1989Warren} since no alternative
  diverges and is equivalent to Merciry's \emph{semidet} adjective.
\end{definition}

\begin{definition}[Operational determinacy (\isdet)]\label{def:is-det}
  Given a program \prog and an atom $g$ we say that
  $\isdet\ \prog\ g$ iff $\isDetCmd{t}$. It is even stronger than
  $\isfunc\ \prog\ g$ since it leaves no choice points at all.
\end{definition}

The analysis we propose guarantees terminating functionality on
the original program \prog and operational determinacy on a tranformation
$\prog^!$ or the original \prog if the runtime indexes clauses deep enough.

We augment the grammar for predicate signatures as follows:

% The determinacy definition that adhere the most to our need is the one
% considering the arguments marked as input as terms that are consumed by the
% interpreter and that allow to produce determinalistically the output. %In order
% % to differenciate input from output in an application like $\predVar\ \vec{t}$,
% % we use the notation $t_i$ and $t_o$ to respectively separate the input and the
% % output arguments of \predVar.
% In order to differenciate relations from deterministic predicates, and also
% to distinguish input from output arguments, we change the signature of predicate
% as follows:
%
\begin{align}
  psign & ::= [\detI \mid \relI]\ \vecL{ty} \funsep \vecL{ty}
  %\label{eq:pred}
\end{align}

% Eg: a TC instance may not exist, or may exist and be granted to be unique
% without exploring any other choice point. Come mettere once intorno a ogni call
% e dare errore se l'utilizzatore aggiunge a un certo punto una clausola
% che rende questa "ottimizzazione" falsa.

% A predicate is either deterministic (\detI) or relational (\relI). The symbol
% \funsep\ separates input from output arguments. We let \expI\ be a shortcut for
% for all terms of type $data$ and let \ctx\ be a mapping from predicate names to
% their determinacy type (dtype). For now, the dtype is simply the type of the
% predicate where all $data$ have been replaced with \expI. For example, if
% \elpiIn{succ} is a function two arguments of type \elpiIn{int} the first being
% the input the second being the output, then ``$\ctx\ \texttt{succ} =
% \dtype{\detI}{[\expI]}{[\expI]}$''. By convention we say that in a predicate
% signature all inputs comes before outputs.

We resume below the definitions and the properties
that are needed for determinacy checking.
%
% Under the hypothesis to work
% with program statically mode-checked, a necessary condition for a
% predicate to be deterministic is that no two clauses can be applied successfully
% on the same predicate call. Two clauses respecting this property are called
% mutually-exclusive.
%
To define this property, we first need to introduce some the auxiliary
definitions.

% \begin{coqcode}
%   Definition mutual_exclusive_head '(p i _ :- _) '(p i' _ :- _) :=
%     not (exists ~\subst\!\!~, ~\unifyCmd{i1}{i2}{\EmptySubst}{\subst}~)

%   Definition mutual_exclusive_cut c1 c2 :=
%     before c1 c2 -> with_cut c1

%   Definition mutual_exclusive prog p :=
%     forall c1 c2, c1 <> c2 -> c1 \in prog p -> c2 \in prog p ->
%       mutual_exclusive_clause c1 c2 \/ mutual_exclusive_cut c1 c2

% \end{coqcode}


\begin{definition}[Mutual-exclusion with \cut\ (\mutExclCut)]
  Given two clauses
  $c_1$ and $c_2$ such that $c_1$ is defined before $c_2$,
  the body of $c_1$ contains a \cut.
  \label{def:mut-excl+cut}
\end{definition}

\begin{lemma}[Mutually-exclusive \cut\ property]
  Given any $\ctx$ and any program $\prog$ that holds two clauses $c_1$ and
  $c_2$ for $\pred$ such that $\mutExclCut\ \ctx\ c_1\ c_2$,
  then any $\wellModed\ (\pred\ \vec{t})$ is such that
  $$
    \mathcal{F}(\prog, \pred\ \vec{t}, \subst, \EmptyList) = [\alts[_1], a_2]
    \to
    \runCmdQ{a_1}{\EmptyList}{\subst}{a'} \to
    \runCmdQ{a_1}{a_2}{\subst}{a'}
$$
  \label{th:mut-excl+cut}
\end{lemma}
\begin{proof}
  Given the definition of $\mathcal{F}$ and \mutExclCut we have that
  $a_1 = (\subst,[\ldots, (\prog, \cut, \EmptyList), post])$.
  Since $a_1$ succeeds with an empty list of alternative we know that
  \ref{rule:cut} is executed on $\runCmdQ{(\subst',\cut, post)}{a}{\subst}{a'}$,
  hence $\runCmdQ{(\subst',post)}{\EmptyList}{\subst}{a'}$.
  The same condifuration is reached by starting with $\runCmdQ{a_1}{a_2}{\subst}{a'}$
  but \ref{rule:cut} is executed on $\runCmdQ{(\subst',\cut, post)}{a @ a_2}{\subst}{a'}$.
  % just with a different set of alternative
  % By induction on the derivation rules (\cref{fig:basic-interp}). The interesting case is the rule
  % \ref{rule:call} when the heads $c_1$ and $c_2$ unify both with the current goal. If
  % this is the case, then two cases should be taken into account: 1) the \cut\
  % inside the body of $c_1$ is reached while running the program. In this case
  % the \cut, will cut away the clause $c_2$ since, by contruction, it cannot
  % appear in the cut-alternatives. 2) The \cut\ is not reached, that is, a failure
  % occurs before reaching it. This means that the clause $c_1$ is not applied on
  % the goal. In both cases both clauses cannot be applied simultaneously on the
  % same goal.
\end{proof}

\begin{definition}[Mutual-exclusion (\mutExcl)]
  We say that $\mutExcl~\ctx\ \prog$ holds iff
  for all \pred such that $\ctx\ \pred = \dtype{\detI}{\_}{\_}$ and
  for all (distinct) clauses $c_1$ and $c_2$ in \prog\ \pred, 
  $\mutExclHeads\ \ctx\ c_1\ c_2\ d \lor \mutExclCut\ c_1\ c_2$ holds.
  \label{def:mut-excl}
\end{definition}

% \begin{lemma}[Mutually-exclusion property]
%   Given a context \ctx\ and a program \prog, if $\mutExcl\ \ctx\ \prog$ then for
%   any call $\pred\ \vec{t}$ with ground inputs, it exists at most one clause that can be
%   successfully applied on $\pred\ \vec{t}$.
%   \label{th:mut-excl}
% \end{lemma}

% \begin{proof}
%   By \cref{th:mut-excl-head,th:mut-excl+cut}
% \end{proof}

The second condition for determinacy is the following:

\newcommand{\detAtom}{\texttt{det\_call}}

\begin{definition}[Deterministic term application (\detAtom)]
  Given a context \ctx\, the term $\pred\ \vec{t}$ is a deterministic
  call if $\ctx\ \pred = \dtype{\detI}{\_}{\_}$
\end{definition}

\begin{definition}[Deterministic premises (\detPrem)]
  We say that $\detPrem\ \ctx\ \prog$ holds iff
  for all \pred such that $\ctx\ \pred = \dtype{\detI}{\_}{\_}$ and for all clause
  $(\clauseCmd{\pred}{\vec{t}}{b_1\dots b_n}) \in \prog\ \pred$ then
  $(\exists b_j = \cut \land \forall k > j, \detAtom\ b_k) \lor \forall j, \detAtom\ b_j$.
  \label{def:det-prem}
\end{definition}

This amout to say that in program \prog, a predicate \pred has deterministic
premises if the bodies of all its clauses either 1) have a \cut\ followed by
calls to deterministic predicates or 2) have only calls call to deterministic
predicates.

% \begin{lemma}[Deterministic premises property]
%   Let \prog and \pred be a program
%   $$\forall c, \prog\ \pred = [c] \to \wellModed\ \prog \to \runCmd{[\goalCmd{\prog}{\callCmd{p}{i}{o}}{\EmptyList}]}{\EmptyList}{\EmptySubst}{a}{\subst}, a = \EmptyList$$
%   \label{th:det-prem}
% \end{lemma}
% \begin{proof}
%   By induction on the derivation in \cref{fig:basic-interp}. The interesting
%   case is the \ruleCall. Since, by hypothesis, it exists only one clause $c$
%   implementing \pred in \prog, the recursive call has a new fresh list of goals
%   \g to treat (the premises $c$) and no choice points. Note that, by the
%   definition of the $\mathcal{F}$ function, all goal in \g has the empty list as
%   cut-alternatives. Two cases should be taken into account. 1) \g has a \cut.
%   Reaching the \cut\ will cut away all choice points which are set again to the
%   \empty list. After the \cut, all premises are call to deterministic
%   predicates. By induction hypothesis, this premises generates no choice points,
%   therefore the returned list of alternatives is the empty list, as expected. 2)
%   there is not \cut in \g, similarly to the previous case, all premises are call
%   to deterministic predicate, therefore we can conclude the proof using the
%   induction hypothesis.
% \end{proof}

\begin{definition}[Determinacy checking (\detCheck)]
  $\detCheck\ \ctx\ \prog = \mutExcl\ \ctx\ \prog \land \detPrem\ \ctx\ \prog$
  \label{def:det-check}
\end{definition}

% \begin{definition}[Neck-cut program: \ensuremath{\progCut}]  
%   Given a context \ctx\ and program \prog, we note \progCut to be a the same
%   program as \prog where all clauses ``\clauseCmd{\pred}{\vec{t}}{\vec{b}}'' with no
%   \cut\ in $\vec{b}$ such that \pred\ is noted deterministic in \ctx\ have been
%   replaced by the clauses with the shape ``\clauseCmd{\pred}{\vec{t}}{\cut,
%   \vec{b}}''.
% \end{definition}
% {goal[]}{alts[]}{subst}{alts_res}{subst_res}
% \begin{theorem}[\ensuremath{\progCut} with \mutExcl]  
%   % Il programma deve essere well moded, i goal devono avere input ground\dots

%   Given a context \ctx\ and a program \prog, if $\mutExcl\ \ctx\ \prog$ and
%   \runCmd{[\goalCmd{\prog}{(\pred\ \vec{t})}{\EmptyList}]}{\EmptyList}{\subst}{\alt}{\subst[']}\ 
%   % with goals using \prog\ as program
%   hold then   
%   \runCmd{[\goalCmd{\prog[^!]}{(\pred\ \vec{t})}{\EmptyList}]}{\EmptyList}{\subst}{\EmptyList}{\subst[']}, 
%   % $suffix (clean(\alt['])) \alt$.
%   % $$\mutExcl\ \ctx\ \prog \to 
%   % \forall \g\ \alt\ \subst\ \alt[_1]\ \subst[_1],
%   % \runCmd{\g}{\alt}{\subst}{\alt[_1]}{\subst[_1]} \to
%   % \runCmd{\g}{\alt}{\subst}{\alt[_2]}{\subst[_2]} \to
%   % (\alt[_1], \subst[_1]) = (\alt[_2], \subst[_2])$$
% \end{theorem}

% \begin{proof}
%   We have two cases to analyse.
%   Case 1: the run with \prog implies the run with \progCut. We 
% \end{proof}

\begin{definition}[$\prog^!$ and the set $I^!$ of index-cut]
  $\prog^!$ is $\prog$ where all the clauses of
  predicates \pred s.t. $\ctx \pred = \dtype{\detI}{\_}{\_}$
  forcibly contain a \cut. In particular each cluase
  $c = \clauseCmd{\pred}{\vecL{t}}{al}$ s.t. $\cut \not\in al$
  is replaced by $\clauseCmd{\pred}{\vecL{t}}{\cut, al}$.
  We call these cuts \emph{index-cut}, and their set $I^!$.
\end{definition}

\begin{definition}[Index-cut erasure $|\cdot|$]
  Given an alternative $a = (\subst, \vecL{gl})$ we write
  $|a|$ the procedure of filtering out index-cuts, i.e.
  $|a| = (\subst,\ [ (\prog^!,\ g,\ \vecL{|al|})\ \mathbf{if}\ g \not\in I^! \ \mid\ (\prog^!,\ g,\ al) \in \vecL{gl}])$
\end{definition}

\begin{lemma}[Same exec $\prog$ and $\prog^!$]
  Given a well moded \prog{} and
  a well moded call $\pred\ \vec{t})$, if $\detCheck\ \ctx\ \prog$
  and $\runCmd{[(\prog,\pred\ \vecL{t},\EmptyList)]}{\EmptyList}{\EmptySubst}{a}{\subst}$
  we have that
   $\runCmd{[(\prog^!,\pred\ \vecL{t},\EmptyList)]}{\EmptyList}{\EmptySubst}{a'}{\subst}$
  (for the same \subst) and moreover
  $\forall x \in a / |a'|, \runCmdFQ{x}{\EmptyList}$
\end{lemma}
\begin{proof}
  We proceed by induction on the derivations in \cref{fig:basic-interp}. The
  most significant case to consider is \ref{rule:call}. Let $\vec{c}$ denote the
  result of $\prog\ \pred$. The function $\mathcal{F}$ produces a list of
  alternatives $\alt$, where each $a_i \in \alt$ consists of the unification
  between each term in $\vec{t}$ and the corresponding terms in the head of $c_i$,
  followed by the body of $c_i$.
  
  Let $\alt = a_1, \dots, a_s, \dots, a_n$, where $a_s$ is the first alternative that
  can be successfully applied to the initial goal. We distinguish between two
  cases:  
  1) $a_s$ contains a \cut.
  % 2) $a_s$ does not contain a \cut.
  
  In the first case, by hypothesis $\detPrem\ \ctx\ \prog$, the alternative
  $a_s$ has the form $b_1, \dots, b_x, \dots, b_m$, where $b_x = \cut$, and for
  all $b_j \in b_{x+1},\dots,b_m$, $b_j$ is a call to a deterministic predicate.
  The presence of the \cut\ discards the alternatives $a_{s+1},\dots,a_n$ as
  well as all choice points generated by the execution of the goals
  $b_1,\dots,b_{x-1}$. By \wellModed\ \prog, we know that
  the sequential execution of each subgoal in $b_{x+1},\dots,b_m$ has ground
  inputs, therefore, by the induction hypothesis, the execution of the goals
  $b_{x+1},\dots,b_m$ produces alternatives with no solution. Consequently, the
  goal is proved in this case.
  
  % In the second case, where $a_s$ does not contain a \cut, the hypothesis
  % guarantees that all goals in $a_s$ are calls to deterministic predicates. By
  % \wellModed\ \prog, we know that the sequential execution
  % of each subgoal in $a_s$ has ground inputs, therefore, by the
  % induction hypothesis, the execution of these goals produces alternatives
  % $\alt[']$ with no solution. The final list of alternatives returned by the
  % call to \run is the concatenation of $\alt[']$ and $a_{s+1},\dots,a_n$. We
  % need to prove that:
  % $$\forall a_i \in \alt['] @ (a_{s+1},\dots,a_n), \lnot (\exists \alt\
  % \subst['], \runCmd{a_i}{\EmptyList}{\EmptySubst}{\alt}{\subst[']})$$
  
  
  This holds for the alternatives in $\alt[']$. For any alternative $a_k \in
  (a_{s+1},\dots,a_n)$, the mutual exclusion hypothesis \mutExcl\ \ctx\ \prog\
  ensures that no alternative derived from clauses of \pred\ declared
  chronologically after $c_s$ can unify with the goal $\pred\ \vec{t}$, since
  every term in input position in $\vec{t}$ is ground. This completes the proof.
%
  % \cref{th:mut-excl} that at most one clause $c$ successfully applies on the
  % call to \pred. By definition of $\mathcal{F}$\todo{there are also unif}, the new goals \g are made from
  % the term in the body of $c$ and all of them will have by construction the empty list as
  % cut-alternatives. We need to treat two cases. 1) \g has a cut. If all the
  % goals before the \cut\ succeed, then all the choice points generated are cut
  % away. Moreover, since, by hypothesis, all the goals after the \cut\ are calls
  % to deterministic predicates, and since, \wellModed\ \prog,
  % we know that all of these calls have at most one solution.
  % We can now use the induction hypothesis on the remaining goals
  % claiming that in the end the empty list of alternatives is produced,
  % completing the proof for this case. 2) \g has not cut. The proof is similar
  % to the previous one after having reached the cut.
\end{proof}


\begin{theorem}[Determinacy checking property]\label{th:det}
  For all predicate \pred such that $\ctx\ \pred = \dtype{\detI}{\_}{\_}$ we
  have that
  $$\wellModed\ \prog\ \land\ \wellModed\ (\pred\ \vec{t})\ \land\ \detCheck\ \ctx\ \prog\ \to \isdet\ \prog^!\ (\pred\ \vec{t})$$
\end{theorem}
\begin{proof}
since all rules have a cut, and that \ref{rule:call} stored in the goal
the cut-to alternatives at call time, and that we start the computation
with the alternatives \EmptyList, any list of atoms following the cut is
executed with empty alternatives. This smaller computation is made
of det predicates (det check premise), hence by induction they also return the
empty alternative list.
\end{proof}

\subsection{Digression on  $\prog^!$}

The contruction $\prog^!$ inserts in $\prog$ cuts that corresponds to
an \emph{eager} version of $\mathcal{F}$, that instead of always
generating an alternative for each clause filters upfront clauses
whose head unifies with the goal. Most implementations of 
logic programming languages index clauses so to discard upfront as many
rules as possible, for example using a rete algorithm.
The eager operational semantics is faithful to an implementation that indexes
clauses on all input deep enough to discriminate them whenever the \mutExclHeads
check does. This semantics would make theorem \ref{th:det} hold for \prog
rather than $\prog^!$.
\todo{e allora perchè non la facciamo così subito?}

\subsection{Digression on \isdet}

We insist on \isdet{} rather than \isfunc{} or functional as in~\cite{1989Warren}
becase the former gives the programmer a more precise indication of the
run time behavior of a predicate labelled as \func. If \texttt{mem} and \texttt{len}
are flagged as such, then the programmer knows that this silly piece of
code terminate in linear time.

\begin{elpicode}
silly L V :- mem 1 L, len L N, N = V.
\end{elpicode}

Upon failure under a notation of functional as in~\cite{1989Warren} the complexity
could be quadratic since a mem (without a cut) is still a function. If mem
was \isfunc{} the code would still be linear but with the cost of a choice point.
With \isdet{} the code is operationally equivalent to the following code where
the complexity, even in case of failure, is very apparent.

\begin{elpicode}
once P :- P, !.
silly L V :- once (mem 1 L), once (len L N), N = V.
\end{elpicode}

We are so concerned with failure in case of performance because of Elpi's
application as the runtime for type class resolution in the interactive prover
Rocq: the user experience crytically relies on quick feedback from the system.

% A definition of functional as in warren, or like 
% \begin{definition}[Functionality (\isfunc)]\label{def:is-func}
%   Given a program \prog and a term $t$,
%   \isdet\ is defined as follows:
%   $$\forall a\ \subst, \isFuncCmd{t}$$
% \end{definition}
% does not have this guarantee.

% \begin{coqcode}
% Definition ~\customlabel{detpred}{\texttt{det\_pred}}~(~\prog~: prog) (p: pn) :=
%   forall ~$i$~ ~$o$~ ~$a$~ ~\subst~(HG: ground i) 
%     (H : ~\runCmd{[\goalCmd{\prog}{\callCmd{p}{i}{o}}{\EmptyList}]}{\EmptyList}{\EmptySubst}{a}{\subst}~), ~$a$~ = ~\EmptyList~.
% \end{coqcode}

% The definition above explains what it means for a predicate to be deterministic. 
% The idea is that in a given program \prog and a predicate $p$,
% if for any call to $p$ with arbitrary input and output terms
% starting with the empty substitution and the empty list of alternatives,
% we have a solution, i.e. the couple $(a, \subst)$ then the list of
% alternatives $a$ is empty. This essentially means that any functional
% predicate produces no choice points.

% Following the literature, this claim is proven true:

% \begin{theorem}
%   Let \pred be a deterministic-annotated predicate, the following holds
%   \begin{coqcode}
%     Theorem ~\customlabel{is_detpred}{\texttt{det\_pred\_prop}}~(~\prog~: prog) (p: pn) :=
%       forall (HM : well_moded ~\prog\!\!~) (HD: det_check ~\prog\!\!~),
%           det_pred ~\prog~p
%   \end{coqcode}    
% \end{theorem}

% This to say that for any well-moded (hypothesis \coqIn{HM}) and
% determinacy-checked (hypothesis \coqIn{HD}) program and a predicate \pred such,
% then \pred is a deterministic predicate.

% \subsection{Contributions and paper structure}

% In our paper we will provide a description about a new dynamic mode and
% a new static determinacy
% checkers to verify that clauses are consistent wrt the signature the predicate has. We
% introduce these concepts with the \elpi programming language. We start by a
% light version of \elpi in the first-order setting, i.e. with no higher-order variables.
% In this part we explain our notion of modes, which have an inpact
% on the dynamic interpretation of the program. This will force us to slightly
% modify the interpreter in \cref{fig:basic-interp}. Moreover, thanks to these modes, we show that
% to statically guarantee the determinacy property of deterministic predicates
% we don't need any static mode analysis.

% In the second part of the paper we will extend the intepreter so that it can\todo{there are 3 parts}
% work with higher-order variables, hereditary-arrop clauses insertion and local
% $\forall$-quantified variable declaration. Here predicates will also take
% propositions as arguments. Thanks to this extention we will propose a new mode
% checking algorithm working with a new definition of groundness, called
% \textit{input-ground}. The signature of a predicate can be annotated so that
% output arguments are guaranteed to be deterministic. This will make the
% determinacy checker to analyse not only deterministic clauses but also relational
% one, since a check should be performed wrt the determinacy annotation of its
% outputs.