\section{Determinacy analysis of Horn Clauses with input matching}
\label{sec:basic-elpi}

\begin{elpicode}
  once (p X). % mercury fails ground, elpi OK.
\end{elpicode}

It is interesting to note that mode checking under the groundness condition is
sometime too restrictive. In some situation it is in fact sufficient to work
with term that are "enough" ground to guarantee the wanted properties. As an
example, both \cite{1994apt-oc} and \cite{2002overton}, even though they
researches concern different areas, present a version of this mode checking with
"enough" instantiated terms together with some condition of variable linearty.

In our paper, we will combine these ideas. In particular,
since \elpi is used as a
meta-language for proof verification
\cite{tassi2018,tassi2019,tassi2023,fissore2023,fissore2024}, we
need to work with a higher-order setup where inputs (and outputs) may not be
fully instantiated: the role of the search engine is to potentially assign
unification variables. In the first part of the paper, we will introduce the
seamantics of the input mode which is used in \elpi.
In the second part, we extend it so that it works with predicates taking
predicate calls as arguments.


As anticipated in the end of \cref{sec:modes}, the hypothesis that input
argument are ground, such as in \cref{th:det} is a too strong condition for our
use case. In automatic proof search, the input arguments may contain flexible
terms. They will actually assigned by the search engine. Similarly, proof search
may produce non-ground output terms. This means that \cref{def:well-moded}
should be relaxed.

In our first-order prolog system we work with the same data structures described
in the previous section, however, we change the unification algorithm wrt the
mode of the terms that are being unified.

\subsection{Modes and \match}
\label{sec:elpi-modes}

% Mode checking in this setting is performed using the classical groundness
% verification where term groundness is derived from their flow in the body of a
% clause. We start with the hypothesis that a term in input position in the head
% of a clause is ground. The premises in the body representing calls to predicates
% must be called with ground input terms, while output are supposed to become
% ground. At the end of the body analyse, we check that the output terms in the
% head of the clause has become ground. If this is not the case, or if a call in
% the body is done with a non-ground term in input position a mode-checking error
% is raised.

The modes we authorize in this setting are two, even though we call them
the input and the output
mode, ther interpretation we attach to them is quite different. 
% As explained at the very end of \cref{sec:modes}, we want predicates
% to be called with non-ground input terms, therefore
% the meaning we attach to our modes is quite particuar wrt what
% can be found in the literature.

We start from the concept of terms read and write as
sketched in \cite{1991ait-wam}. Essentially, in a call, a term in input position is an
object received in read mode. This means that, if the entry
term is a variable and the corresponding term in the head of the clause is
rigid, unification fails: we cannot write in input in the head of a clause.

On the other hand, it is always possible to unify a non-flexible input term with
a variable if that variable appears in the head of the clause: we are consuming
the pieces of information of the input to select the clause in the program. 

% Finally, no
% constraints are imposed on output terms: they are used to produce information
% and therefore they can be written. In a call an output is not forced to be a
% variable to be instantiated, but also a compound term.

We refer to this special type of unification as \match. Similar to the \unify
procedure, we use the notation \matchCmd{t_1}{t_2}{\subst}{\subst[']} to denote
the \match\!ing between two terms $t_1$ and $t_2$, transforming, if
possibile, an initial substitution \subst into a final substitution \subst['].

\def\vars{\texttt{vars}}

\begin{definition}[The \match procedure]
  Let \coqIn{vars(t)} be a function that returns the variables in a term
  \coqIn{t}. Then \match is defined as follows:
  \vspace{-1em}
  $$\forall\ t_1\ t_2\ \subst\ \subst['], \unifyCmd{t_1}{t_2}{\subst}{\subst[']} \land \vars\ (\sigma t_1) = \vars\ (\subst['] t_1)$$
  \vspace{-2em}
  % \begin{coqcode}
  %   Definition ~\matchCmd{t_1}{t_2}{\subst}{\subst[']}~ :=
  %     ~\unifyCmd{t_1}{t_2}{\subst}{\subst[']}~ /\ 
  %       ~$\forall$~ v, v \in vars(~$t_1$~) -> is_var ~(\subst['] $t_1$)~
  % \end{coqcode}
\end{definition}

As a mean of example, consider following program.

\begin{elpicode}
  pred p i:int, o:int.
  p 1 1.          % p1
  p X 2 :- X = 7. % pX
\end{elpicode}


The predicate \elpiIn{p} is decorated with a type\&mode signature. It tells not
only that the first two arguments should be of type \elpiIn{int}, but also that
the first argument is an input (\modeAlone{i}) and the second an output
(\modeAlone{o}). This means that the query \elpiIn{p Y Z} succeed exactly once:
the rule \elpiIn{p1} could not be applied, since the variable \elpiIn{Y} is in
input (i.e. read mode) and cannot be instantiated to $1$ in the head of the
clause. Note, that the application of \elpiIn{pX} on the query succeed and
producing the substitution $\subst = \{Y \mapsto 7, Z \mapsto 2\}$: \elpiIn{Y}
can be instantiated in the body of a clause. Moreover, the query
\elpiIn{p 1 Z} has one solution with $\subst = \{Z \mapsto 1\}$ due to the
application of \elpiIn{p1}. Note that the rule \elpiIn{pX} is a valid choice
point for the query: the head unifies with the query assigning the local
$\exists$variable \elpiIn{X} to $1$, but a failure will occur in the body
while unifying the value of \elpiIn{X} and \elpiIn{7}.

\begin{corollary}[\match is not reflexive]
  The \match operator is not reflexive:
\end{corollary}
\begin{proof}
  A counter-example: \matchCmd{1}{X}{\EmptySubst}{\{X \mapsto 1\}},
  but \matchCmd{X}{1}{\EmptySubst}{\text{\xmark}}.
\end{proof}

\begin{lemma}[\match: unification of right terms]
  Given three terms $t$, $t_1$, and $t_2$:
  $$\forall\ \subst_1\ \subst_2, 
    \matchCmd{t}{t_1}{\EmptySubst}{\subst_1} \to 
    \matchCmd{t}{t_2}{\EmptySubst}{\subst_2} \to 
    \subst_1\ t = \subst_2\ t $$
  \vspace{-2em}
  \label{th:match-right}
\end{lemma}

\begin{proof}
  By hypothesis, $\subst_1\ t = \subst_1\ h_1$ and $\subst_2\ t = \subst_2\
  h_2$. Due to the definition of \match and since $t$ is the term passed in
  input in both \match, no variables in $t$ is assigned in neither
  $\subst_1$ nor $\subst_2$, therefore $\subst_1 t = t$ and $\subst_2 t = t$.
  Now, after some rewriting, we have $\subst_1\ h_1 = \subst_2\ h_2$, which 
  concludes the proof.
\end{proof}

% Moreover, \elpi provides a way to further control the unification on input
% arguments. The user can put the \uvar keyword in front of a variable name in a
% input argument. This tells the unification engine to unify this head term with
% only flexible term. For example, we can add the rule ``\elpiIn{pUX} := \elpiIn{p
% (uvar X) 2 :- X = 7}'' to the previous database. The \uvar keyword does not
% allow the call \elpiIn{p 1 Z} to be unified with \elpiIn{pUX} since \elpiIn{1}
% is not a variable.

% We think that the combination of the input mode and the \uvar keyword give
% the user a powerful tool to  control how unification is dynamically performed
% at runtime.

We add the new term to the language:
% \begin{coqcode}
%   | UnifyM (t1:tm) (t2:tm) : atom
% \end{coqcode}
$$tm ::= ... \mid tm =_m tm$$

The introduction of dynamic modes requires modifying the interpreter so that the
\match procedure is called when unification is performed on input terms. To
achieve this, we need to slightly adjust the $\mathcal{F}$ function used by the
\ref{rule:call}, as follows:\todo{riscrivere con indici diversi}%
% $$
% \mathcal{F}(\prog, \pred, i, o, \subst, \alt) := 
%   [(\subst, (
%       \Cons{(\prog, i =_m i', \alt)}
%         \Cons{(\prog, o = o', \alt)}
%           {[(\prog, g, \alt) \mid g \in bs]})) \mid \clauseCmd{\pred}{i'\ o'}{bs} \in \prog\ \pred]
% $$
%
\begin{align*}
  \mathcal{F}(\prog, \pred, \vec{t}, \subst, \alt) :=
  \Bigg[\bigg(\subst,
    \Big(
    &\big[(\prog, (\vec{t}_i)_x =_m (\vec{u}_i)_x, \alt) \mid 0 \leq x < \text{len }\vec{t}_i\big] \atsign \\
    &\quad\big[(\prog, (\vec{t}_o)_x = (\vec{u}_o)_x, \alt) \mid 0 \leq x < \text{len }\vec{t}_o\big] \atsign\\
    &\qquad\big[(\prog, g, \alt) \mid g \in bs\big]
    \Big)\bigg) \mid \clauseCmd{\pred}{\vec{u}}{bs} \in \prog\ \pred\Bigg]
\end{align*}

The main difference is that the usage of the $=_m$ to indicate that the
unification between input arguments in the goal and in the head of the clause
should be performed using the \match procedure.

Finally the derivation system in \cref{fig:basic-interp} is extended with the
rule in \cref{fig:interp-match}.

\begin{figure}
  
  \ruleMatchM{1}
  
  \caption{Dynamic semantics: rule for \match}
  \label{fig:interp-match}
\end{figure}


% \textcolor{red}{\textbf{TODO}}: add the derivation rule for the $=_m$ atom
% Recall:

% The \textit{unify rule} (\ruleUnif) is applied when a unification $t_1 =_m t_2$
% occurs in the head of the current goal list. Depending on $m$, which can be
% either $i$ or $o$, it calls respectively the \unify or the \match (see
% \cref{sec:elpi-modes}) algorithm between the two terms $t_1$ and $t_2$ from the
% substitution \subst and returns the updated substitution \subst[']. Finally the
% \run\ procedure is called the list of remaining goals \g and the new
% substitution \subst['].

\subsection{Determinacy checker for prolog with \match}


\begin{definition}[Mutually-exclusive heads (\mutExclHeads) at $d$]
  \label{def:mut-excl-head}
  % \begin{coqcode}
  %   Definition ~\customlabel{mutexcl}{\texttt{mutual\_exclusive}}\prog \pred\!\!~:
  %     ~$\forall\ i1\ o1\ bo1\ i2\ o2\ bo2$~ (H1: ~\clauseCmd{p}{i1\ o1}{bo1}~ \in ~$\prog\ p$~) (H2: ~\clauseCmd{p}{i2\ o2}{bo2}~ \in ~$\prog\ p$~),
  %         not (exists ~\subst\!\!~, ~\unifyCmd{i1}{i2}{\EmptySubst}{\subst}~)
  % \end{coqcode}
  Given a context \ctx\ and two clauses $c_1$ and $c_2$ with head,
  respectively, $\pred\ t_1 \ldots t_n$ and $\pred\ u_1 \ldots u_n$.
  Let $\ctx\ \pred = \dtype{\relI}{i_1 \ldots i_k}{\_}$, then we say that
  $\mutExclHeads\ c_1\ c_2\ d$ holds iff $d \leq k\ \land\ \nUnify\ t_d\ u_d$.
\end{definition}

This static check is used to justify the fact that, at run time, either
$c_1$ or $c_2$ is used for a given goal. For this to be true one needs
its discriminating argument at position $d$ to be ground in the call.
The reasoning goes as follows.

% \begin{lemma}[Split transitivity] Given
% two terms $t_1$ and $t_2$ such that $\nUnify~ t_1\ t_2$, there is no ground term
% $t_3$ such that $\unifiable\ t_1\ t_3$ and $\unifiable\ t_3\ t_2 $.
% \end{lemma}

\begin{lemma}[Mutually-exclusive heads property]
  \label{th:mut-excl-head}
  Given a context $\ctx\ $and two clauses $c_1$ and $c_2$
  with heads, respectively, $\pred\ t_1 \ldots t_n$ and $\pred\ u_1 \ldots u_n$.
  % let $\vec{t}_i$ and $\vec{u}_i$ be the inputs arguments of $\vec{t}$ and $\vec u$ respectively.
  % forall vector of \textit{ground} terms $\vec{v}$,
  $$\mutExclHeads\ \ctx\ c_1\ c_2\ d \to \lnot \exists v\ s.t.\ 
    \ground\ v\ \land\ \unifiable\ v\ t_d \land\ 
    \unifiable\ v\ u_d$$
  \vspace{-2em}
\end{lemma}
\begin{proof}
  By contradiction, let $v$ be a ground term $t_d$ and $u_d$. This
  means that there exists two substitutions $\subst_1$ and $\subst_2$ s.t.
  $\subst_1 v = \subst_1 t_d$
  and $\subst_2 v = \subst_2 u_d$. Since $v$ is ground the equations can be
  simplified to $v = \subst_1 t_d$ and $v = \subst_2 u_d$, hence by transitivity
  $\subst_1 t_d = \subst_2 u_d$. However, by definition of $\mutExclHeads\ \ctx\ c_1\ c_2\ d$
  we have that $\nUnify\ t_d\ u_d$: 
  % for any substituions
  % $\subst[']_1$ and $\subst[']_2$, we have $\subst[']_1\ t_d \neq \subst[']_2\ u_d$,
  a contradiction since $\subst_1 \cup \subst_2$ unifies $t_d$ with $u_d$ and
  we can form that substitution since
  $\dom\ \subst_1 \cap \dom\ \subst_2 = \emptyset$ because
  the domains 
  $\vars\ t_d$ and $\vars\ u_d$ are disjoint (the clause variables are fresh
  at each application) and since the there are no variabels in the codomain,
  since all terms are subterms of $v$ that is ground.
\end{proof}


% The general idea is that a logic program allows to express relations, but,
% sometimes it is also needed to express \textit{directed} relations, where arguments are
% differenciated between inputs and output. Said in an other way, output arguments
% can be derived from input arguments. It is often the case that the user of a
% logic programming langauge tend, in most of cases, to express directed
% predicates. The typical example of this need is the \texttt{append} predicate
% aiming to concatate two lists.

% In a prolog-ish program without modes, the following program:

% \begin{elpicode}
%   append [X|Xs] L [X|L'] :- append Xs L L'. % app1
%   append [] L L.                            % app2
% \end{elpicode}

% \noindent
% makes the query ``\elpiIn{append Y [] L, 0 = 1}'' to diverge.
% Here the variable \elpiIn{Y} is unified with a list of infinite
% length, the rule \texttt{app1} being continously applied.

% In \twelf \cite{1996pfenning}, which is an implementation of \lamprolog, mode
% checking is extended to work with local nominal variables and higher-order
% variable unification within the pattern fragment,

% Modes are there to avoid this situation. The most widespread mode definition
% in the literature are two: the input
% mode and the output mode. The idea is that each predicate is annotated with a
% mode signature, and a static mode checker verifies that the clauses of the
% program are consistent with the mode declrations of the predicates. Essentially,
% in the head of a clause, 1) terms appearing in input position are supposed to be
% ground whereas 2) terms in output position must become ground in the body of the
% clause. Within each premise of the body, 3) terms appering in output positions become
% ground while 4) terms appearing in input positions are checked to be ground. If
% condition 2) or 4) are not satisfied a mode compilation error is raised.

\begin{definition}[Well-moded program and well-moded call (\wellModed)]\label{def:well-moded}
We say $\wellModed\ \prog$ if the static analysis given in \cite{1996pfenning}\todo{cita anche altri}
succeeds. We say $\wellModed\ (\pred\ \vecL{t})$ if
$\ground\ t$ for all $t \in \vecL{t_i}$.
\end{definition}

% \begin{definition}[$\fail\ a\ al$]
% We say $\fail\ a\ al$ iff $\runCmdFQ{a}{al}$
% \end{definition}

\begin{theorem}[Mutually-exclusive clauses property]
  Given any $\ctx$ and any predicate $\prog$ that holds two clauses $c_1$ and
  $c_2$ for $\pred$ such that $\mutExclHeads\ \ctx\ c_1\ c_2\ d$,
  then any $\wellModed\ (\pred\ \vec{t})$ is such that
  $$
    \mathcal{F}(\prog, \pred\ \vec{t}, \subst, \alts) = [\alts[_1], a_2]
    \to
    \runCmdQ{a_1}{\EmptyList}{\subst}{a'} \to
    \runCmdFQ{a_2}{\EmptyList}
    % \lnot \exists \subst' a'', \runCmdQ{a_2}{\EmptyList}{\subst[']}{a''}
$$
    
  \label{th:mut-excl-head}
\end{theorem}
% \begin{proof}Follows from \ref{th:mut-excl-head}
% \end{proof}





% The definition above can be rephrased as follows: a program \prog is well moded
% if for any (binary in our setup) predicate \pred called with a ground input
% \texttt{i} and any output term \texttt{o}, if the call succeeds producing a
% substitution \subst['] then the application of that substitution to \texttt{o}
% is a ground term.

\subsection{Static analysis: Operational determinacy}
\label{sec:det}

Our objective is to indentify predicates that repsent mathamtical
functions rather than relations.
The literature on determinacy analysis goes beyond this coarse categorization,
for example by identifying functions with an empty or full
domain~\cite{1996henderson} or predicate that are observably functions in the sense that
that can return multiple times the same result, or diverge~\cite{1989Warren}.

We are interested in identifying predicates that leave no choice points~\ref{def:is-def}
called \emph{semidet} in \cite{1996henderson}, or in the wording of \cite{nakamura1986}
are \emph{operationally deterministic}.

\begin{definition}[Terminating functionality (\isfunc)]\label{def:is-func}
  Given a program \prog and an atom $g$ we say that
  $\isfunc\ \prog\ g$ iff $\isFuncCmd{t}$. It is stronger than
  functional in the sense of~\cite{1989Warren} since no alternative
  diverges and is equivalent to Merciry's \emph{semidet} adjective.
\end{definition}

\begin{definition}[Operational determinacy (\isdet)]\label{def:is-det}
  Given a program \prog and an atom $g$ we say that
  $\isdet\ \prog\ g$ iff $\isDetCmd{t}$. It is even stronger than
  $\isfunc\ \prog\ g$ since it leaves no choice points at all.
\end{definition}

The analysis we propose guarantees terminating functionality on
the original program \prog and operational determinacy on a tranformation
$\prog^!$ or the original \prog if the runtime indexes clauses deep enough.

We augment the grammar for predicate signatures as follows:

% The determinacy definition that adhere the most to our need is the one
% considering the arguments marked as input as terms that are consumed by the
% interpreter and that allow to produce determinalistically the output. %In order
% % to differenciate input from output in an application like $\predVar\ \vec{t}$,
% % we use the notation $t_i$ and $t_o$ to respectively separate the input and the
% % output arguments of \predVar.
% In order to differenciate relations from deterministic predicates, and also
% to distinguish input from output arguments, we change the signature of predicate
% as follows:
%
\begin{align}
  \func & ::= [\detI \mid \relI]\ \vecL{ty} \funsep \vecL{ty}
  %\label{eq:pred}
\end{align}

% Eg: a TC instance may not exist, or may exist and be granted to be unique
% without exploring any other choice point. Come mettere once intorno a ogni call
% e dare errore se l'utilizzatore aggiunge a un certo punto una clausola
% che rende questa "ottimizzazione" falsa.

% A predicate is either deterministic (\detI) or relational (\relI). The symbol
% \funsep\ separates input from output arguments. We let \expI\ be a shortcut for
% for all terms of type $data$ and let \ctx\ be a mapping from predicate names to
% their determinacy type (dtype). For now, the dtype is simply the type of the
% predicate where all $data$ have been replaced with \expI. For example, if
% \elpiIn{succ} is a function two arguments of type \elpiIn{int} the first being
% the input the second being the output, then ``$\ctx\ \texttt{succ} =
% \dtype{\detI}{[\expI]}{[\expI]}$''. By convention we say that in a predicate
% signature all inputs comes before outputs.

We resume below the definitions and the properties
that are needed for determinacy checking.
%
% Under the hypothesis to work
% with program statically mode-checked, a necessary condition for a
% predicate to be deterministic is that no two clauses can be applied successfully
% on the same predicate call. Two clauses respecting this property are called
% mutually-exclusive.
%
To define this property, we first need to introduce some the auxiliary
definitions.

% \begin{coqcode}
%   Definition mutual_exclusive_head '(p i _ :- _) '(p i' _ :- _) :=
%     not (exists ~\subst\!\!~, ~\unifyCmd{i1}{i2}{\EmptySubst}{\subst}~)

%   Definition mutual_exclusive_cut c1 c2 :=
%     before c1 c2 -> with_cut c1

%   Definition mutual_exclusive prog p :=
%     forall c1 c2, c1 <> c2 -> c1 \in prog p -> c2 \in prog p ->
%       mutual_exclusive_clause c1 c2 \/ mutual_exclusive_cut c1 c2

% \end{coqcode}


\begin{definition}[Mutual-exclusion with \cut\ (\mutExclCut)]
  Given two clauses
  $c_1$ and $c_2$ such that $c_1$ is defined before $c_2$,
  the body of $c_1$ contains a \cut.
  \label{def:mut-excl+cut}
\end{definition}

\begin{lemma}[Mutually-exclusive \cut\ property]
  Given any $\ctx$ and any program $\prog$ that holds two clauses $c_1$ and
  $c_2$ for $\pred$ such that $\mutExclCut\ \ctx\ c_1\ c_2$,
  then any $\wellModed\ (\pred\ \vec{t})$ is such that
  $$
    \mathcal{F}(\prog, \pred\ \vec{t}, \subst, \EmptyList) = [\alts[_1], a_2]
    \to
    \runCmdQ{a_1}{\EmptyList}{\subst}{a'} \to
    \runCmdQ{a_1}{a_2}{\subst}{a'}
$$
  \label{th:mut-excl+cut}
\end{lemma}
\begin{proof}
  Given the definition of $\mathcal{F}$ and \mutExclCut we have that
  $a_1 = (\subst,[\ldots, (\prog, \cut, \EmptyList), post])$.
  Since $a_1$ succeeds with an empty list of alternative we know that
  \ref{rule:cut} is executed on $\runCmdQ{(\subst',\cut, post)}{a}{\subst}{a'}$,
  hence $\runCmdQ{(\subst',post)}{\EmptyList}{\subst}{a'}$.
  The same condifuration is reached by starting with $\runCmdQ{a_1}{a_2}{\subst}{a'}$
  but \ref{rule:cut} is executed on $\runCmdQ{(\subst',\cut, post)}{a \atsign a_2}{\subst}{a'}$.
  % just with a different set of alternative
  % By induction on the derivation rules (\cref{fig:basic-interp}). The interesting case is the rule
  % \ref{rule:call} when the heads $c_1$ and $c_2$ unify both with the current goal. If
  % this is the case, then two cases should be taken into account: 1) the \cut\
  % inside the body of $c_1$ is reached while running the program. In this case
  % the \cut, will cut away the clause $c_2$ since, by contruction, it cannot
  % appear in the cut-alternatives. 2) The \cut\ is not reached, that is, a failure
  % occurs before reaching it. This means that the clause $c_1$ is not applied on
  % the goal. In both cases both clauses cannot be applied simultaneously on the
  % same goal.
\end{proof}

\begin{definition}[Mutual-exclusion (\mutExcl)]
  We say that $\mutExcl~\ctx\ \prog$ holds iff
  for all \pred such that $\ctx\ \pred = \dtype{\detI}{\_}{\_}$ and
  for all (distinct) clauses $c_1$ and $c_2$ in \prog\ \pred, 
  $\mutExclHeads\ \ctx\ c_1\ c_2\ d \lor \mutExclCut\ c_1\ c_2$ holds.
  \label{def:mut-excl}
\end{definition}

% \begin{lemma}[Mutually-exclusion property]
%   Given a context \ctx\ and a program \prog, if $\mutExcl\ \ctx\ \prog$ then for
%   any call $\pred\ \vec{t}$ with ground inputs, it exists at most one clause that can be
%   successfully applied on $\pred\ \vec{t}$.
%   \label{th:mut-excl}
% \end{lemma}

% \begin{proof}
%   By \cref{th:mut-excl-head,th:mut-excl+cut}
% \end{proof}

The second condition for determinacy is the following:


\begin{definition}[Deterministic term application (\detAtom)]
  Given a context \ctx\, the term $\pred\ \vec{t}$ is a deterministic
  call if $\ctx\ \pred = \dtype{\detI}{\_}{\_}$
\end{definition}
 
\begin{definition}[Deterministic premises (\detPrem)]
  We say that $\detPrem\ \ctx\ \prog$ holds iff
  for all \pred such that $\ctx\ \pred = \dtype{\detI}{\_}{\_}$ and for all clause
  $(\clauseCmd{\pred}{\vec{t}}{b_1\dots b_n}) \in \prog\ \pred$ then
  $(\exists b_j = \cut \land \forall k > j, \detAtom\ b_k) \lor \forall j, \detAtom\ b_j$.
  \label{def:det-prem}
\end{definition}

This amout to say that in program \prog, a predicate \pred has deterministic
premises if the bodies of all its clauses either 1) have a \cut\ followed by
calls to deterministic predicates or 2) have only calls call to deterministic
predicates.

% \begin{lemma}[Deterministic premises property]
%   Let \prog and \pred be a program
%   $$\forall c, \prog\ \pred = [c] \to \wellModed\ \prog \to \runCmd{[\goalCmd{\prog}{\callCmd{p}{i}{o}}{\EmptyList}]}{\EmptyList}{\EmptySubst}{a}{\subst}, a = \EmptyList$$
%   \label{th:det-prem}
% \end{lemma}
% \begin{proof}
%   By induction on the derivation in \cref{fig:basic-interp}. The interesting
%   case is the \ruleCall. Since, by hypothesis, it exists only one clause $c$
%   implementing \pred in \prog, the recursive call has a new fresh list of goals
%   \g to treat (the premises $c$) and no choice points. Note that, by the
%   definition of the $\mathcal{F}$ function, all goal in \g has the empty list as
%   cut-alternatives. Two cases should be taken into account. 1) \g has a \cut.
%   Reaching the \cut\ will cut away all choice points which are set again to the
%   \empty list. After the \cut, all premises are call to deterministic
%   predicates. By induction hypothesis, this premises generates no choice points,
%   therefore the returned list of alternatives is the empty list, as expected. 2)
%   there is not \cut in \g, similarly to the previous case, all premises are call
%   to deterministic predicate, therefore we can conclude the proof using the
%   induction hypothesis.
% \end{proof}

\begin{definition}[Determinacy checking (\detCheck)]
  $\detCheck\ \ctx\ \prog = \mutExcl\ \ctx\ \prog \land \detPrem\ \ctx\ \prog$
  \label{def:det-check}
\end{definition}

% \begin{definition}[Neck-cut program: \ensuremath{\progCut}]  
%   Given a context \ctx\ and program \prog, we note \progCut to be a the same
%   program as \prog where all clauses ``\clauseCmd{\pred}{\vec{t}}{\vec{b}}'' with no
%   \cut\ in $\vec{b}$ such that \pred\ is noted deterministic in \ctx\ have been
%   replaced by the clauses with the shape ``\clauseCmd{\pred}{\vec{t}}{\cut,
%   \vec{b}}''.
% \end{definition}
% {goal[]}{alts[]}{subst}{alts_res}{subst_res}
% \begin{theorem}[\ensuremath{\progCut} with \mutExcl]  
%   % Il programma deve essere well moded, i goal devono avere input ground\dots

%   Given a context \ctx\ and a program \prog, if $\mutExcl\ \ctx\ \prog$ and
%   \runCmd{[\goalCmd{\prog}{(\pred\ \vec{t})}{\EmptyList}]}{\EmptyList}{\subst}{\alt}{\subst[']}\ 
%   % with goals using \prog\ as program
%   hold then   
%   \runCmd{[\goalCmd{\prog[^!]}{(\pred\ \vec{t})}{\EmptyList}]}{\EmptyList}{\subst}{\EmptyList}{\subst[']}, 
%   % $suffix (clean(\alt['])) \alt$.
%   % $$\mutExcl\ \ctx\ \prog \to 
%   % \forall \g\ \alt\ \subst\ \alt[_1]\ \subst[_1],
%   % \runCmd{\g}{\alt}{\subst}{\alt[_1]}{\subst[_1]} \to
%   % \runCmd{\g}{\alt}{\subst}{\alt[_2]}{\subst[_2]} \to
%   % (\alt[_1], \subst[_1]) = (\alt[_2], \subst[_2])$$
% \end{theorem}

% \begin{proof}
%   We have two cases to analyse.
%   Case 1: the run with \prog implies the run with \progCut. We 
% \end{proof}

\begin{definition}[$\prog^!$ and the set $I^!$ of index-cut]
  $\prog^!$ is $\prog$ where all the clauses of
  predicates \pred s.t. $\ctx \pred = \dtype{\detI}{\_}{\_}$
  forcibly contain a \cut. In particular each cluase
  $c = \clauseCmd{\pred}{\vecL{t}}{al}$ s.t. $\cut \not\in al$
  is replaced by $\clauseCmd{\pred}{\vecL{t}}{\cut, al}$.
  We call these cuts \emph{index-cut}, and their set $I^!$.
\end{definition}

\begin{definition}[Index-cut erasure $|\cdot|$]
  Given an alternative $a = (\subst, \vecL{\vecL{g}})$ we write
  $|a|$ the procedure of filtering out index-cuts, i.e.
  $|a| = (\subst,\ [ (\prog^!,\ g,\ \vecL{|al|})\ \mathbf{if}\ g \not\in I^! \ \mid\ (\prog^!,\ g,\ al) \in \vecL{\vecL{g}}])$
\end{definition}

\begin{lemma}[Same exec $\prog$ and $\prog^!$]
  Given a well moded \prog{} and
  a well moded call $\pred\ \vec{t})$, if $\detCheck\ \ctx\ \prog$
  and $\runCmd{[(\prog,\pred\ \vecL{t},\EmptyList)]}{\EmptyList}{\EmptySubst}{a}{\subst}$
  we have that
   $\runCmd{[(\prog^!,\pred\ \vecL{t},\EmptyList)]}{\EmptyList}{\EmptySubst}{a'}{\subst}$
  (for the same \subst) and moreover
  $\forall x \in a / |a'|, \runCmdFQ{x}{\EmptyList}$
\end{lemma}
\begin{proof}
  We proceed by induction on the derivations in \cref{fig:basic-interp}. The
  most significant case to consider is \ref{rule:call}. Let $\vec{c}$ denote the
  result of $\prog\ \pred$. The function $\mathcal{F}$ produces a list of
  alternatives $\alt$, where each $a_i \in \alt$ consists of the unification
  between each term in $\vec{t}$ and the corresponding terms in the head of $c_i$,
  followed by the body of $c_i$.
  
  Let $\alt = a_1, \dots, a_s, \dots, a_n$, where $a_s$ is the first alternative that
  can be successfully applied to the initial goal. We distinguish between two
  cases:  
  1) $a_s$ contains a \cut.
  % 2) $a_s$ does not contain a \cut.
  
  In the first case, by hypothesis $\detPrem\ \ctx\ \prog$, the alternative
  $a_s$ has the form $b_1, \dots, b_x, \dots, b_m$, where $b_x = \cut$, and for
  all $b_j \in b_{x+1},\dots,b_m$, $b_j$ is a call to a deterministic predicate.
  The presence of the \cut\ discards the alternatives $a_{s+1},\dots,a_n$ as
  well as all choice points generated by the execution of the goals
  $b_1,\dots,b_{x-1}$. By \wellModed\ \prog, we know that
  the sequential execution of each subgoal in $b_{x+1},\dots,b_m$ has ground
  inputs, therefore, by the induction hypothesis, the execution of the goals
  $b_{x+1},\dots,b_m$ produces alternatives with no solution. Consequently, the
  goal is proved in this case.
  
  % In the second case, where $a_s$ does not contain a \cut, the hypothesis
  % guarantees that all goals in $a_s$ are calls to deterministic predicates. By
  % \wellModed\ \prog, we know that the sequential execution
  % of each subgoal in $a_s$ has ground inputs, therefore, by the
  % induction hypothesis, the execution of these goals produces alternatives
  % $\alt[']$ with no solution. The final list of alternatives returned by the
  % call to \run is the concatenation of $\alt[']$ and $a_{s+1},\dots,a_n$. We
  % need to prove that:
  % $$\forall a_i \in \alt['] \atsign (a_{s+1},\dots,a_n), \lnot (\exists \alt\
  % \subst['], \runCmd{a_i}{\EmptyList}{\EmptySubst}{\alt}{\subst[']})$$
  
  
  This holds for the alternatives in $\alt[']$. For any alternative $a_k \in
  (a_{s+1},\dots,a_n)$, the mutual exclusion hypothesis \mutExcl\ \ctx\ \prog\
  ensures that no alternative derived from clauses of \pred\ declared
  chronologically after $c_s$ can unify with the goal $\pred\ \vec{t}$, since
  every term in input position in $\vec{t}$ is ground. This completes the proof.
%
  % \cref{th:mut-excl} that at most one clause $c$ successfully applies on the
  % call to \pred. By definition of $\mathcal{F}$\todo{there are also unif}, the new goals \g are made from
  % the term in the body of $c$ and all of them will have by construction the empty list as
  % cut-alternatives. We need to treat two cases. 1) \g has a cut. If all the
  % goals before the \cut\ succeed, then all the choice points generated are cut
  % away. Moreover, since, by hypothesis, all the goals after the \cut\ are calls
  % to deterministic predicates, and since, \wellModed\ \prog,
  % we know that all of these calls have at most one solution.
  % We can now use the induction hypothesis on the remaining goals
  % claiming that in the end the empty list of alternatives is produced,
  % completing the proof for this case. 2) \g has not cut. The proof is similar
  % to the previous one after having reached the cut.
\end{proof}


\begin{theorem}[Determinacy checking property]\label{th:det}
  For all predicate \pred such that $\ctx\ \pred = \dtype{\detI}{\_}{\_}$ we
  have that
  $$\wellModed\ \prog\ \land\ \wellModed\ (\pred\ \vec{t})\ \land\ \detCheck\ \ctx\ \prog\ \to \isdet\ \prog^!\ (\pred\ \vec{t})$$
\end{theorem}
\begin{proof}
since all rules have a cut, and that \ref{rule:call} stored in the goal
the cut-to alternatives at call time, and that we start the computation
with the alternatives \EmptyList, any list of atoms following the cut is
executed with empty alternatives. This smaller computation is made
of det predicates (det check premise), hence by induction they also return the
empty alternative list.
\end{proof}



TODO: add the uvar to the terms



